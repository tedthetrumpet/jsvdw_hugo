<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Tomorrow sees the launch of The Next Station, a project by Cities and Memory to reimagine the sounds of the London Underground. My contribution to this project is an audio work called if only I had, constructed entirely from a 3&#39;42 recording of a train arriving and departing from Pimlico station.
The title is taken from Spike Milligan’s ‘Adolf Hitler: My Part in his Downfall’:
‘Edgington and I promenaded the decks.">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:title" content="The Next Station – ‘if only I had’" />
<meta property="og:description" content="Tomorrow sees the launch of The Next Station, a project by Cities and Memory to reimagine the sounds of the London Underground. My contribution to this project is an audio work called if only I had, constructed entirely from a 3&#39;42 recording of a train arriving and departing from Pimlico station.
The title is taken from Spike Milligan’s ‘Adolf Hitler: My Part in his Downfall’:
‘Edgington and I promenaded the decks." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/posts/2016-08-22-the-next-station-if-only-i-had/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2016-08-22T00:00:00+00:00" />
<meta property="article:modified_time" content="2016-08-22T00:00:00+00:00" />
<title>The Next Station – ‘if only I had’ | JSvdW Hugo test</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" >
<link rel="canonical" href="http://localhost:1313/posts/2016-08-22-the-next-station-if-only-i-had/">
<link rel="stylesheet" href="/book.min.f8d3666af559e9590215dba2158127976df19ef623d0be35c6765ea14d98350f.css" integrity="sha256-&#43;NNmavVZ6VkCFduiFYEnl23xnvYj0L41xnZeoU2YNQ8=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.6175b1550173d4444cf14a9c2a76b18d5244dc748698e7a65b2768913fd6219d.js" integrity="sha256-YXWxVQFz1ERM8UqcKnaxjVJE3HSGmOemWydokT/WIZ0=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>JSvdW Hugo test</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Works</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/works/2008-02-29-scam/" class="">The Society for Classical and Authentic Music</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-b86813cf18f514c18a53bf1c7586c09d" class="toggle"  />
    <label for="section-b86813cf18f514c18a53bf1c7586c09d" class="flex justify-between">
      <a href="/docs/works/works-section/" class="">Works Section</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/works/works-section/first-page/" class="">First Page</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/works/works-section/second-page/" class="">Second Page</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>











  
<ul>
  
  <li>
    <a href="/posts/"  >
        Blog
      </a>
  </li>
  
</ul>






</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>The Next Station – ‘if only I had’</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents"></nav>



  </aside>
  
 
      </header>

      
      
<article class="markdown book-post">
  <h1>
    <a href="/posts/2016-08-22-the-next-station-if-only-i-had/">The Next Station – ‘if only I had’</a>
  </h1>
  
  <h5>August 22, 2016</h5>



  

  



<p>Tomorrow sees the launch of <a href="http://www.citiesandmemory.com/thenextstation">The Next Station</a>, a project by Cities and Memory to reimagine the sounds of the London Underground. My contribution to this project is an audio work called <a href="https://audioboom.com/boos/4896960-if-only-i-had-pimlico-station"><em>if only I had</em></a>, constructed entirely from a 3'42 recording of a train arriving and departing from Pimlico station.</p>
<p>The title is taken from Spike Milligan’s ‘Adolf Hitler: My Part in his Downfall’:</p>
<p>‘Edgington and I promenaded the decks. Harry stopped: “If only I had a tube.” “Why?” “It’s quicker by tube.”</p>
<p>… an inconsequential pun that has, for some reason, always stuck in mind!</p>
<p>I made this piece as a personal study into the possibility of using <a href="http://toplap.org/">livecoding</a> techniques in <a href="http://supercollider.github.io/">SuperCollider</a> to develop a fixed piece. In recent months I have been very active in exploring coding in this way, particularly in the context of <a href="http://algorave.com/">algorave</a>: <em>if only I had</em> leverages these techinques. Here’s some of the code I used, with explanation:</p>
<p><code>( s.waitForBoot{ Pdef.all.clear; Pbindef.defaultQuant = 4; t = TempoClock.new.tempo_(120/60).permanent_(true); ~path = &quot;/Users/jsimon/Music/SuperCollider Recordings/pimlicoloops/&quot;;</code></p>
<p>This is a remnant of what turned out to be a bit of a false start to the project. My initial idea was to look through the file for shortish sections, in the region of 2-3 seconds long that, when looped, had some sort of rhythmic interest. This was done offline, using <a href="http://www.audacityteam.org/">Audacity</a>. I thought it might be interesting to develop the piece by using these fragments almost in the manner of drum loops, and wrote some code to juxatpose them in various ways at different tempi. This didn&rsquo;t really produce anything very effective however: the material is rather dense and noisy, and when looped together the rhythmic interested was lost in broadband mush of sound.</p>
<p>Instead, I revisited a synth from an earlier project that slices a buffer into 16 pieces for playback:</p>
<p><code>~bufs = (~path ++ &quot;*.aiff&quot;).pathMatch.collect({ |i|  Buffer.read(s, i)}); SynthDef(\slbuf, { |out, buf, slices=16, slice=16, freq=440, sustain=0.8| var myenv, env, start, len, basefreq = 440, rate, sig, sus; rate = freq / basefreq; len = BufFrames.kr(buf); start = (len / slices * slice); sus = BufDur.kr(buf)/16 * sustain * 1.1; myenv = Env.linen(attackTime: 0.01, sustainTime: sus, releaseTime: 0.1); sig = PlayBuf.ar(2, buf, BufRateScale.kr(buf) * rate, startPos: start, loop: 1); env = EnvGen.kr(myenv, 1, doneAction: 2); Out.ar(out, sig * env) }).add;</code></p>
<p>As well as experimenting with reverb, I also had a delay effect in here at one point. Again, the nature of the already fairly resonant material meant that this was not that useful. In the end, I only used the reverb at the very end of the piece as a closing gesture.</p>
<p><code>~rbus = Bus.audio(s, 2); SynthDef(\verb, {|out = 0, room = 1, mix = 1| var sig = FreeVerb.ar(In.ar(~rbus, 2), room:room, mix:mix); Out.ar(out, sig) }).add; s.sync; Synth(\verb);</code></p>
<p>At some point in developing the project, it occured to me to try playing together the sliced material with the orignal file. This seemed to effective, and gave me a clear trajectory for the work: I decided that the finished piece would be the same pop-song length as the original recording. In experimenting with this approach – playing sliced loops in SC at the same time as playing back the whole file in Audacity – I found myself gently fading the original in and out. This is modelled in the synth below: I used an explicit random seed together with interpolated low frequency noise to produce a replicable gesture:</p>
<p><code>~file = &quot;/Users/jsimon/Documents/ Simon's music/pimlico the next station/Pimlico 140516.wav&quot;; ~pimbuf = Buffer.read(s, ~file); s.sync; SynthDef(\pim, { |out=0, start=0, amp = 1| var sig, startframe, env; startframe = start * 44100; RandSeed.ir(1,0); env = EnvGen.kr(Env.linen(sustainTime: ~pimbuf.duration - 9, releaseTime:9)); sig = PlayBuf.ar(2, ~pimbuf, startPos:startframe, doneAction:2) * LFNoise1.kr(1/5).range(0.05, 1.0); Out.ar(out, sig * amp * env); }).add;</code></p>
<p>There was a nice moment in the original where the accelerating electronic motors of the departing train created a seried of overlapping upward glissandi, sounding very like Shepard tones, or rather, the sliding Risset variation. Looking to enhance this gesture, I tried a couple of my own hacks before giving up and turning to a nice class from Alberto de Campo’s <a href="https://github.com/supercollider-quarks/adclib">adclib</a>:</p>
<p><code>~shep = { var slope = Line.kr(0.1, 0.2, 60); var shift = Line.kr(-1,2,60); var b = ~bufs[8]; var intvs, amps; var env = EnvGen.kr(Env.linen(sustainTime:53, releaseTime:7),1,doneAction:2); #intvs, amps = Shepard.kr(5, slope, 12, shift); (PlayBuf.ar(b.numChannels, b, intvs.midiratio, loop: 1, startPos:3*44100) * amps).sum * 0.2 }; s.sync;</code></p>
<p>All of the above is essentially setup material. The gist of the composition was in iterative experimentation with Pbindefs, as can be seen below: trying out different slicing patterns and durations, working with the various segments I&rsquo;d prepared beforehand in Audacity.</p>
<p><code>Pbindef(\a, \instrument, \slbuf, \slice, Pseq((1..8).pyramid(1), 1), \dur, 1/2, \buf, ~bufs[1], \note, 0); Pbindef(\b, \instrument, \slbuf, \slice, Pser((8..15).pyramid(1), 32), \dur, 1/4, \buf, ~bufs[1], \note, 0); Pbindef(\c, \instrument, \slbuf, \slice, Pser((2..5).pyramid(1), 32), \dur, 1/4, \buf, ~bufs[0], \note, 0); Pbindef(\d, \instrument, \slbuf, \slice, Pseq((1..8).pyramid(1), 1), \dur, 1/4, \buf, ~bufs[3], \note, 0); Pbindef(\e, \instrument, \slbuf, \slice, Pseq((1..8).pyramid(1), 1), \dur, 1/4, \buf, ~bufs[3], \note, 12); Pbindef(\f, \instrument, \slbuf, \slice, Pseq((1..8).pyramid(1), 1), \dur, 1/4, \buf, ~bufs[3], \note, [-12,12,24,36]); Pbindef(\g, \instrument, \slbuf, \slice, Pseq((1..8).pyramid(1), 1), \dur, 1/4.5, \buf, ~bufs[3], \note, [12,24,36]); Pbindef(\h, \instrument, \slbuf, \slice, Pseq((1..8).pyramid(1), 1), \dur, 1/5, \buf, ~bufs[3], \note, [-12,12,24,36]); Pbindef(\i, \instrument, \slbuf, \slice, Pseq((1..8).pyramid(12), 1), \dur, 1/6, \buf, ~bufs[3], \note, [-24,-12,12,24,36]); Pbindef(\j, \instrument, \slbuf, \slice, Pseq((1..8).pyramid(1), 1), \dur, 1/7, \buf, ~bufs[3], \note, [-24,-12,12,24,36], \amp, 0.3); Pdef(\k, (instrument: \slbuf, buf: ~bufs[3], slice: 2, note: [-24,-12,12,24,36], amp: 0.5, out:~rbus));</code></p>
<p>s.sync; };</p>
<p>The final composition was produced by running and recording the code below, which uses the handy Psym as a way to sequence the gestures developed above. The code by this point is entirely deterministic, and would produce the same piece on every run. No further editing was done, apart from normalising in Audacity.</p>
<p><code>// start from beginning fork{ Synth(\pim); 2.wait; Psym(Pseq(&quot;aabaccddeeffghiijk&quot;,1).trace).play(t); (60+14+20).wait; &quot;shep&quot;.postln; ~shep.play; 10.wait; &quot;off again&quot;.postln; Psym(Pseq(&quot;aabaccddeeffghiijk&quot;,1).trace).play(t); }; ) s.prepareForRecord s.record s.stopRecording</code></p>
<p>Overall, I&rsquo;m happy with the piece, and glad to have been able to contribute to this very interesting project.</p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents"></nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












