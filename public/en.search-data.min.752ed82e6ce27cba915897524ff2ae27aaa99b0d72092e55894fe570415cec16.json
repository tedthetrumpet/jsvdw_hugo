[{"id":0,"href":"/posts/2023-08-24-el-laberinto-at-new-music-scotland-awards/","title":"'El laberinto' at New Music Scotland awards","section":"Blog","content":"Just heard that my new piece \u0026lsquo;El laberinto\u0026rsquo; for voice, bass clarinet and general MIDI is going to be performed by Stephanie Lamprea and Alex South at the Scottish Awards for New Music 2023 on 1st September.\nI say \u0026rsquo;new piece\u0026rsquo; – effectively this is revisiting and recontextualisation of an earlier piece \u0026lsquo;El laberinto de mi mente\u0026rsquo;.\nHere\u0026rsquo;s what I\u0026rsquo;ve written about the new version:\nThe world has changed a lot since 1998, and I feel much less comfortable about my place in it. Was I only able to become a ‘composer’ thanks to the the middle class white male privilege that gave me the confidence, agency and status to do so? Is there any value to my work, or is it just a self-indulgence? Am I privileged to be able to even ask that question?\nThe writing for the voice and clarinet is inspired by a tradition of wordless virtuoso unison lines most commonly associated perhaps with Carnatic/jazz fusions. The accompaniment makes self-consciously nostalgic use of General MIDI sounds in a Standard MIDI File, rewinding back to those naively happy days of plain text, ISDN dialup and minidiscs.\n"},{"id":1,"href":"/posts/2023-02-05-patternuary-2023/","title":"Patternuary 2023","section":"Blog","content":"During January 2023 a number of people active in the livecoding community participated together in a \u0026lsquo;patternuary\u0026rsquo; https://club.tidalcycles.org/t/patternuary-2023/4474/1 aiming to make one pattern every day during the month.\nSome people worked in TidalCycles https://tidalcycles.org/, while many chose to use the Strudel platform https://strudel.tidalcycles.org/.\nSome of the patterns were posted on the Tidal Club thread above, while many otherers appeared under the #patternuary thread on Mastodon https://post.lurk.org/tags/patternuary.\nGiven the strong likelihood of bitrot, I created a single video https://archive.org/details/jsvdwpatternuary2023 that captures brief excerpts of all of the patterns I made: mostly in Strudel, but also in SuperCollider, Pd and one composition notated in MuseScore.\nThe audio is also released as an album on bandcamp: https://tedthetrumpet.bandcamp.com/album/everyday-jan-63\n(Most of) the code is available as a gist https://gist.github.com/tedthetrumpet/0410ae1cd2ad0a2837a36aca94e5b5ea\n"},{"id":2,"href":"/posts/2022-12-23-livecoding-audacity-the-outcome/","title":"Livecoding Audacity – the outcome","section":"Blog","content":"So, here\u0026rsquo;s how it turned out: attempting to \u0026rsquo;livecode\u0026rsquo; Audacity by saving a file out periodically to SuperCollider. A slow start, but gets more interesting towards the end of the twenty minutes.\nhttps://youtu.be/0YpgHdJY-Kw\nAlso available here https://archive.org/details/nightstream-dec-2022-tedthetrumpet\n"},{"id":3,"href":"/posts/2022-12-20-livecoding-audacity/","title":"Livecoding Audacity","section":"Blog","content":"Had a slightly crazy idea for the TidalClub Night Stream on 2022-12-21 – could I livecode something in Audacity?!?\nObviously the answer is basically no, as you can\u0026rsquo;t edit anything in Audacity while it is playing. So, instead, the plan is to use some of the things in the Generate menu to improvise some sounds: the Risset Drum, Rhythm Track, DTMF Tones and so on.\nOnce I have a minute\u0026rsquo;s worth I, save out a mixdown to disk. Then, I have a script running in SuperCollider that waits a minute, then reloads the latest file exported from Audacity. So, in theory, I have a minute to create the next layer in Audacity while the last layer is playing.\nFor some reason, I decided to bill the performance as a \u0026lsquo;dangdut\u0026rsquo;, so I also have some simple algorithmically generated dangdut-ish material ready to go in SuperCollider that can be played alongside the much more abstract Audacity material.\nQuick proof-of-concept video:\nhttps://youtu.be/x2XVkoGofQ8\n"},{"id":4,"href":"/posts/2021-12-20-the-longest-night/","title":"The Longest Night","section":"Blog","content":"I\u0026rsquo;ve been teaching some of the composition students at the Royal Conservatoire of Scotland how to livecode in Estuary, and we\u0026rsquo;re going to do a short set as part of The Longest Night. Here\u0026rsquo;s the test I just did for that, which sort of counts as another one of my tiny estuary jams – not a very interesting one!\nhttps://youtu.be/bTJdRI9Zhzs\n"},{"id":5,"href":"/posts/2021-12-03-tiny-estuary-jams/","title":"Tiny Estuary Jams","section":"Blog","content":"I seem to have started doing that thing where I post a small piece of work each day: so far, four very short jam sessions in Estuary:\nhttps://youtu.be/MeCpvXLMQe4\nhttps://youtu.be/b5MQBuA5SWA\nhttps://youtu.be/ddkhm-JRj5I\nhttps://youtu.be/dRgQwRuUYsM\n"},{"id":6,"href":"/posts/2021-03-10-gamelan-sounds-in-garageband-on-ipad/","title":"Gamelan sounds in GarageBand on iPad","section":"Blog","content":"This posting shows how I was able to get the sounds of the pelog half of the Spirit of Hope gamelan here in Glasgow to work in GarageBand on an iPad.\nFirst install an app called \u0026lsquo;SoundFonts\u0026rsquo; from the App Store: it\u0026rsquo;s £4.99.\nGo to this link https://archive.org/download/sohgamelanbalunganpelog, and download the file called SoH Gamelan balungan pelog.sf2\nThe file should end up saved in the Downloads folder in iCloud Drive.\nOpen the SoundFonts app and click the + button.\nThis took me straight to the correct file in iCloud Drive: you might have to browse to find it though. Select the file to import it to the SoundFonts app.\nOnce you select the sound called \u0026lsquo;balungan_pelog\u0026rsquo; you should be able to play it. You might need to change octave to get all of the sounds, there should be slenthem, demung, saron and peking.\nRepeat the process above to download the other soundfont, that includes gongs, kenongs, kethuk and drums. Here is the link https://archive.org/download/so-h-gamelan-gongs-drums-etc-pelog\nTo use the sounds in GarageBand, you need to find – I don\u0026rsquo;t know what it is called, this track browser thing! – and select the \u0026lsquo;External\u0026rsquo; pane.\nSelect the SoundFonts icon\nAnd you can now play and record tracks using the gamelan samples in GarageBand!\n"},{"id":7,"href":"/posts/2020-12-21-looking-back-over-the-year/","title":"Looking back over the year","section":"Blog","content":"The tempation to \u0026lsquo;share\u0026rsquo; on proprietary online platforms means that I don\u0026rsquo;t document my work here as frequently as I should! So, here\u0026rsquo;s a roundup of some things I\u0026rsquo;ve produced this year: as much a reminder to myself as anything else.\nFebruary ‘Perang Gagal: a Series of Inconclusive Battles’ at ICLC Limerick https://www.youtube.com/watch?v=N6PXoRHwWFY https://github.com/tedthetrumpet/Perang-Gagal March two performances at Euleroom Equinox, a busk followed later by the \u0026lsquo;official\u0026rsquo; set http://equinox.eulerroom.com/schedule.html https://youtu.be/AmF-L1WfPl8 https://youtu.be/jDl_ALEq4Zs track \u0026rsquo;threequal\u0026rsquo; on SoundArtist.ru mixtape https://radio.syg.ma/episodes/soundartist-ru-11-algorave-equinox April curated two gamelan soundfonts, released on archive.org https://archive.org/details/sohgamelanbalunganpelog https://archive.org/details/so-h-gamelan-gongs-drums-etc-pelog May Algovoids performance https://youtu.be/H4HbByRDC1s July Performed with Gamelan Naga Mas at the Network Music Festival video still not available :( https://networkmusicfestival.org/programme/performances/naga-mas-golden-dragons-go-online/ October 7 Calls collaboration with Mags Smith of Good Vibrations https://youtube.com/playlist?list=PLITN4U9SUP7WEhfrWKeIyTLzH_z6FqI_r December two sets (sort of!) at Euleroom Solistice: \u0026lsquo;official\u0026rsquo; performance and crazy spontaneous chaotic jam session: coming soon coming soon "},{"id":8,"href":"/posts/2020-12-14-gamelan-samples/","title":"Gamelan samples","section":"Blog","content":"This is just a quick post to pull together links to a number of places online where I have offered up gamelan sounds for download. It\u0026rsquo;s all a bit chaotic! Most of these are from the pelog Spirit of Hope instruments in Glasgow, sometimes retuned. Some of them may be from other sources that I\u0026rsquo;ve forgotten about.\nFrom my perspective, these are all inteneded to be CC0 \u0026lsquo;No rights reserved\u0026rsquo; – you can do what you like with them!\nIf I\u0026rsquo;ve accidentally uploaded someone else\u0026rsquo;s sample here and you want me to take it down, please let me know.\nhttps://freesound.org/people/tedthetrumpet/packs/14/\nhttps://freesound.org/people/tedthetrumpet/packs/1797/\nhttps://archive.org/details/so-h-gamelan-gongs-drums-etc-pelog\nhttps://archive.org/details/sohgamelanbalunganpelog\nhttps://github.com/tedthetrumpet/Perang-Gagal/tree/master/SuperCollider/arum\n"},{"id":9,"href":"/posts/2020-03-14-sound-from-supercollider-to-obs-on-macos/","title":"Sound from SuperCollider to OBS on macOS","section":"Blog","content":"The principle here is that sound is sent from SuperCollider to the virtual audio driver BlackHole, and from BlackHole to OBS. You then listen to the sound through OBS.\nInstall https://github.com/ExistentialAudio/BlackHole\nSet the mac sound output to \u0026lsquo;BlackHole 16ch\u0026rsquo; using the widget in the menu bar:\nBoot or reboot the server in SuperCollider – this is a key step, the SC server will not pick up a change of audio device without a fresh boot or a reboot:\nAfter boot, check that the SC post window says \u0026lsquo;\u0026ldquo;BlackHole 16ch\u0026rdquo; Output Device\u0026rsquo;:\n(If you\u0026rsquo;re using Tidal you\u0026rsquo;ll need to run SuperDirt.start here again.)\nIn OBS, click on \u0026lsquo;Settings\u0026rsquo; and go to the \u0026lsquo;Audio\u0026rsquo; pane. Set \u0026lsquo;Mic/Auxillary Audio\u0026rsquo; to \u0026lsquo;BlackHole 16ch\u0026rsquo; and \u0026lsquo;Monitoring Device\u0026rsquo; to \u0026lsquo;Built-in Output\u0026rsquo;:\nIn OBS, look for a gear icon for settings in the Audio Mixer panel select \u0026lsquo;Advanced Audio Properties\u0026rsquo;:\nUnder Audio Monitoring select \u0026lsquo;Monitor and Output\u0026rsquo;:\nPlay a sound in SuperCollider. In OBS, turn up the slider in the Audio Mixer Panel, and you should see the Mic/Aux slider picking up sound:\nSound should now be playing from SC into OBS and through into your speakers/headphones. Adjust volume as usual from the widget in the menu bar.\nUpdate: it seems that on macOS 10.15 you may need to go back to the volume widget in the menu bar and select the output you want to hear there. (I can\u0026rsquo;t test this directly, I\u0026rsquo;m still on 10.13).\n"},{"id":10,"href":"/posts/2020-02-04-subsonic-workshop-and-algorave/","title":"Subsonic workshop and algorave","section":"Blog","content":"Claire Quigley and Miriam Iorweth are curating a \u0026lsquo;Subsonic\u0026rsquo; workshop and algorave at the Scottish Submarine Centre on Friday 20 March as part of the Euleroom Equinox 2020 livecoding event.\nThere is an introductory workshop 1930 to 2030, followed by an algorave 2030 to 1030. The workshop is free, the algorave is pay what you want.\nIf you\u0026rsquo;d like to take part in the workshop or are interested in performing at the algorave, contact Miriam:\ncrotchetymusic@gmail.com\neflyers:\nSubsonic Algorave 2020.pdf Subsonic Algorave Workshop.pdf\n"},{"id":11,"href":"/posts/2019-12-31-livecoding-brass/","title":"Livecoding brass","section":"Blog","content":"As 2019 draws to a close, I’m spending some time getting ready for the International Conference on Livecoding in February in Limerick. I put in two proposals. The first of these was to be called The ‘All-Pressure No-Method’ System, and would have involved me working with four live brass players. I say ‘would have’: this has had to be abandoned, we were not able to fund the travel and accomodation for the players.\nThe central idea, however, is one I’d like to return to. Inspired particularly by the work of Kate Sicchio in livecoding dancers, the intention was to livecode the brass players by means of a repertoire of typed and projected instructions. Here’s a demo video of the concept:\nhttps://youtu.be/8vk53ZiDN_s\n"},{"id":12,"href":"/posts/2019-12-31-livecoding-gamelan/","title":"Livecoding gamelan","section":"Blog","content":"The work that I will be taking to ICLC 2020 in Limerick is entitled ‘Perang Gagal: a Series of Inconclusive Battles’, and is a collaboration with Professor Mel Mercier at the Irish Word Academy of Music and Dance. I will performing livecode in SuperCollider as part of a small gamelan ensemble let by Mel. Here’s the demo video I submitted to the conference call:\nhttps://youtu.be/yN1STGvmRqY\nI had thought that the eventual piece would be straightforward to devise, but it is proving trickier than I thought. There are couple of limitations. We won’t have access to a full gamelan for the conference. I had hoped to visit Limerick to work with the players in advance, but that has not proved possible: instead, I am going to send sketches of the material I am working on to Mel, and we will put the piece together during the conference.\nThe third limitation is around pulse. I want this piece to be rhythmic, but I do not feel confident about trying to get SuperCollider to follow the tempo and pulse of a live ensemble of gamelan musicians. Consequently, I am having to devise material where SuperCollider establishes some sort of groove that the live players will follow.\nSo far I have four potential sections for the piece. As ever, I am reworking existing materials. ‘fibblesticks’ and ‘Adrift \u0026amp; Afloat’ are ‘counting pieces’ that employ numerical frameworks to allow performers to play together in time, while leaving pitch inderminate: or rather, when working with the gamelan, projecting the entire complement of available notes, pelog in this case.\nI have on a number of occasions performed a sort of quasi-Javenese gamelan texture in SuperCollider, using samples of the Spirit of Hope instruments here in Glasgow. For Limerick, I have reworked this by adding a balungan part for the live players.\nThe fourth section for the piece is new, and is based around a couple of musical ideas that occured to me in a dream and that were still in my head on awakening:\nMany of my musical ideas originate in this way!\n"},{"id":13,"href":"/posts/2019-12-31-that-syncing-feeling/","title":"That syncing feeling","section":"Blog","content":"In order to be able to work up sketches for ‘Perang Gagal’ at ICLC in Limerick, I wanted to use Logic to compose demos of the material for the live players that I could then improvise with in SuperCollider. This poses the problem of how to sync the pulse and tempo between the two programmes, which proved annoyingly difficult to accomplish!\nIdeally, I would have liked to set the tempo in SuperCollider for Logic to follow. A straightforward way to do this would have been for SC to send MIDI clock and have Logic follow but, annoyingly, Logic does not support slaving to MIDI clock.\nAccording to the Logic help, it should be possible to sync to an audio click from Logic. I couldn’t get this to work, and nobody on the Logic Users Group seemed to be able to help either.\nThe eventual solution was less than perfect. I used Logic to send MIDI clock, and had SuperCollider slave to that. This involved using the MIDISyncClock extension from H. James Harkins ddwMIDI quark. Not perfect, but got the job done.\nWhat did work very well indeed was the recently released Blackhole tool for passing audio between mac applications. I’d definitely recommend this as a replacement for Soundflower!\n"},{"id":14,"href":"/posts/2019-05-31-radio-automata/","title":"Radio Automata","section":"Blog","content":"Here\u0026rsquo;s the collaboration that Bill Whitmer and I did for Radiophrenia\nhttps://youtu.be/FpvYl_PwvTk\n"},{"id":15,"href":"/posts/2019-05-22-algorave-at-radiophrenia/","title":"Algorave at Radiophrenia","section":"Blog","content":"This week I\u0026rsquo;m taking my algorave work in a new direction. In collaboration with Bill Whitmer, we are going to be presenting a half-hour show called \u0026lsquo;Radio Automata Live in the Studio\u0026rsquo; as part of Radiophrenia, a temporary art radio station broadcasting from the CCA in Glasgow.\nThe idea for the show is: if the last remaining creative decisions in broadcast radio were entirely automatic, would anyone notice? Bill has been experimenting with algorithmically generated text and chatbots for the spoken part of the show. For my part, I\u0026rsquo;m going to be creating cut-up mashups using the slicing techniques I\u0026rsquo;ve been developing in SuperCollider.\nIn previous work along these lines, I\u0026rsquo;ve always used source material that was either explicitly open source, or, at least, grey-area material that I was unlikely to be sued for, like old TV themes and midi module demo songs.\nIn this show, for the first time I\u0026rsquo;m taking a so-sue-me approach, using… well, I won\u0026rsquo;t give the game away, but some *very* well known material indeed, arising from \u0026lsquo;suggestions\u0026rsquo; \u0026lsquo;made\u0026rsquo; by the bots Bill has been working with. In early experiments this is sounding very interesting indeed. Watch this space, or rather, listen to this wavelength!\n23rd May 2019 1100-1130 87.9FM across Glasgow "},{"id":16,"href":"/posts/2019-03-26-livecoding-with-robert-henderson/","title":"Livecoding with Robert Henderson","section":"Blog","content":"Improviser Núria Andorrà visited Glasgow in March to teach on the International Collaboration in Contemporary Improvisation module at the Royal Conservatoire of Glasgow. My colleage Una McGlone took the opportunity to organise a gig for her at Hairdressers, in collaboration with a number of Glasgow improvisers.\nI did a short set alongside trumpet player Robert Henderson, who I have known for many years: in fact, I know him from the period around twenty years ago where I myself was active as a gigging trumpet player! For this performance, I used a bank of sounds that I have created using purely mechanical sounds from a trumpet, the metal, valves, valve slides and so forth. It\u0026rsquo;s always slightly problematic livecoding alongide an actual analog musician, as it is not easy to respond particularly rapidly to another player. However, Robert and I enjoyed playing together and managed to create some satisfying musical gestures together.\nNo recording made, unfortunately!\n"},{"id":17,"href":"/posts/2019-02-18-algorave-at-sound-thought/","title":"Algorave at Sound Thought","section":"Blog","content":"I shared an algorave spot at Sound Thought with Claire Quigley, that was streamed as part of the TOPLAP 15th anniversary stream. You can see her set here and mine is here, although I have to say not that happy with the way my performance turned out on the day. The rehearsal was better:\nhttps://youtu.be/zQwASJEnYEY\nAs you can see, combining my livecoding work with my passion for table tennis! And, in fact, this was a new technical discovery just the day before: it is possible to use Atom to livecode simultaneously in Hydra and SuperCollider, using a plugin for SC. I\u0026rsquo;m not sure this is intended behaviour, but in practice if you have Hydra running in Atom and then switch to a page of SC code, the Hydra visuals run on behind that code.\nAmongst other things, Claire is a colleage of mine at the Royal Conservatoire of Scotland, where she teaches coding to the music education students. We\u0026rsquo;re hoping to do more work together in the future.\n"},{"id":18,"href":"/posts/2019-01-28-callout-for-scottish-algo-ravers-16-2-2019/","title":"Callout for Scottish algo-ravers 16-2-2019","section":"Blog","content":"I\u0026rsquo;m looking for music and/or visual artists working with live code who are interested in joining me for an improvised algorave as part of Sound Thought 2019.\n‘Livecoding’ is a practice where creative artists who work with computer code perform live, often producing music and/or visuals, with the audience typically able to watch the evolution of the code on a projected screen. ‘Algorave’ is a subgenre where the aim is to produce beat-driven music and/or visuals for dancing.\nExamples of the kind of software we\u0026rsquo;re talking about include:\nMusic: Sonic Pi http://sonic-pi.net/ TidalCycles http://tidalcycles.org/ FoxDot http://foxdot.org/ SuperCollider https://supercollider.github.io/ Troop https://github.com/Qirky/Troop Estuary http://intramuros.mcmaster.ca:8002/ Gibber http://gibber.cc/ ChucK http://chuck.cs.princeton.edu/ Pd https://puredata.info/ Overtone http://overtone.github.io/\nVisuals: Hydra https://github.com/ojack/hydra LiveCodeLab https://livecodelab.net/ VEDA https://veda.gl/ PraxisLIVE https://www.praxislive.org/ Processing https://processing.org/ fluxus http://www.pawfal.org/fluxus/ The Force https://videodromm.com/The_Force/ LiveCoder http://livecoder.net/\nMore about algorave https://algorave.com/ and livecoding https://toplap.org/\nDrop me an email on js.vanderwalt@rcs.ac.uk if interested!\n"},{"id":19,"href":"/posts/2019-01-21-iclc-2019-madrid/","title":"ICLC 2019 Madrid","section":"Blog","content":"Some reflections on the International Conference on Livecoding 2019 in Madrid.\nThe play-and-tell workshop that I helped put together with Evan Raskob and Renick Bell was, as intended, a low key and informal way for people to share their individual practices in livecode. Of particular interest to me was Dimitris Kyriakoudis showing how he uses heavily customised keyboard shortcuts in emacs as a way to be completely fluent when performing: as he put it, \u0026rsquo;typing should not get in the way of livecoding performance\u0026rsquo;. There were also some very interesting links to my mind between his Timelines system – \u0026lsquo;all music is a function of time\u0026rsquo; and Neil C Smith\u0026rsquo;s \u0026lsquo;AMEN $ Mother Function\u0026rsquo; performance that worked by chopping up a wavetable as a function of time.\nAs well as that session, I also had input to a paper entitled \u0026lsquo;Towards Improving Collaboration Between Visualists and Musicians at Algoraves\u0026rsquo; co-authored by – deep breath – Zoyander Street, Alejandro Albornoz, Renick Bell, Guy John, Olivia Jack, Shelly Knotts, Alex McLean, Neil C Smith, Atsushi Tadokoro, J. S. van der Walt and Gabriel Rea Velasco. The creation of this paper was itself an interesting process, beginning with a conversation in Sheffield, and then continuing with us writing the paper collaboratively in a shared online space. Guy presented the paper, you can see that here.\nA stand-out performance for me was Maia Koenig\u0026rsquo;s \u0026lsquo;RRayen\u0026rsquo;, using some sort of hand-held games console. Great energy: I can\u0026rsquo;t seem to find a video of her performing at ICLC, but here she is doing the piece elsewhere.\nOf the many new livecoding systems presented, I was rather taken by Balázs Kovács slighly bonkers Makkeróni \u0026lsquo;web-based audio operating system\u0026rsquo;, kind of like an online shared bash shell that plays music.\nAlso very interesting was Alejandro Franco and Diego Villaseñor and presenting their Nanc-in-a-Can Canon Generator. The cultural backround was fascinating, with an attention to reclaim Nancarrow as a Mexican composer as explained in the talk.\nI\u0026rsquo;ve never been to Madrid before, but found it was an easy place to be: dry, cold, comfortable and easy to get around. ICLC 2020 is to be in Limerick, fairly local for me, so I\u0026rsquo;ll be looking to present or perform there as well.\n"},{"id":20,"href":"/posts/2018-12-29-werk-stadig/","title":"werk stadig","section":"Blog","content":"Here is the piece I contributed to the Sounding Nature project on Cities and Memory:\nhttps://clyp.it/btdilbxd\nIt is a reworking of an audio file called ‘093 SOUTH AFRICA savannah polyrhythms’. As someone who spent part of their childhood in South Africa, the bird sounds in the source recording are very familiar to me: most particularly the distinctive monotonous call of Streptopelia capicola, the Ring-necked Dove, or, as I used to call it, the Cape Turtle Dove, the name given in the edition of Roberts’ Birds of Southern Africa that I owned at the time. In the current edition of Roberts the call is transliterated as ‘work harder’, but in the older volume it is given in Afrikaans as ‘werk stadig’ which, given the slightly harsher sound of that language, actually works rather better.\nI always thought ‘werk stadig’ meant ‘work steadily’ but it seems a more accurate translation would be ‘work slowly’. Whichever way: for several years now I have been working steadily, or slowly, through a process of learning the SuperCollider programming language. This composition is to some extent a study in that language: yet another attempt to use livecoding approaches as a means to develop a fixed piece. New ideas in this work include FFT as a means of cleaning up the original recording, and the use of a Routine to script JITLib objects in time.\n"},{"id":21,"href":"/posts/2018-09-01-interview-at-sheffield-algorave/","title":"Interview at Sheffield Algorave","section":"Blog","content":"A short interview that Reverb Magazine did with me at the Sheffield Algorave 01/09/2018 – talking about combining livecoding, gamelan samples, and trumpet playing.\nhttps://youtu.be/wX51frpG0TY\n"},{"id":22,"href":"/posts/2018-07-13-raving-the-netbook-again/","title":"Raving the netbook again","section":"Blog","content":"Once again happily proving to myself how possible it is to work with open-source software on basic hardware. Just upgraded to Ubuntu Studio 18.04 on a refurb 11\u0026quot; Dell Inspiron netbook, and built SuperCollider 3.9.3 from source. Here\u0026rsquo;s an algorave-ish test track made using this setup:\nhttps://clyp.it/5d3lo4na\nSome new code idioms:\nPlazy({Pseq((0..15).scramble,4)}).repeat(inf) is easier to type than\nPn(Plazy({Pseq((0..15).scramble,4)})) and similarly\nPseq([2,6,4,7],inf).stutter(32) instead of\nPstutter(32, Pseq([2,6,4,7],inf)) also\nPseq((0..15).scramble,inf).clump(3) "},{"id":23,"href":"/posts/2018-04-21-livecoding-erraid/","title":"Livecoding Erraid","section":"Blog","content":"https://flic.kr/p/fCkH4E\nOn a number of occasions I have used sounds collected at a particular location as a coherent set of resources for a livecoded set. For the last week I\u0026rsquo;ve been in retreat on with the community on the isle of Erraid, which has been a welcome break from the city!\nOne of the features of the island is the \u0026lsquo;observatory\u0026rsquo;. This is a circular tin structure, about two meters across by three high: a restored remnant of the building of the Dubh Artach lighthouse that took place there between 1867 and 1872.\nThe sound world inside this unusual structure is distinctive. I took some recordings (available on freesound.org, or they will be once the finish uploading), that I am going to be using in a livecoded SuperCollider improvisation this Monday during one of the \u0026lsquo;Sonic Nights\u0026rsquo; series at the Royal Conservatoire of Scotland, where staff and students diffuse new electroacoustic works on a multi-channel sound system. If it seems practical, I may stream the performance as well.\n"},{"id":24,"href":"/posts/2018-04-15-not-algorave/","title":"Not algorave","section":"Blog","content":"I\u0026rsquo;m interested in now taking the SuperCollider livecoding techniques that I\u0026rsquo;ve developed in the context of algorave and applying them to the creation of fixed media sound works. Here is one, using some prepared piano samples that Dr Kurt James Werner has been kind enough to put online.\n[audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2018/04/pylon-country.mp3\"][/audio]\npylon-country.mp3\nIt\u0026rsquo;s not perfect: there is still a strong element of improvisation in this way of working, and there are places in this track where, on listening back, I might have wished to have performed differently. A compromise, perhaps, between the raw and the cooked.\n"},{"id":25,"href":"/posts/2018-04-12-livecode-improvisation-with-anne-liis-poll/","title":"Livecode improvisation with Anne-Liis Poll","section":"Blog","content":"As part of the team that organised the third METRIC Improvisation Intensive at the Royal Conservatoire of Glasgow, I did not have as much time as I might have liked to improvise myself. I was pleased however to be joined for an impromptu livecoded session by Anne-Liis Poll, Professor of Improvisation at the Estonian Academy of Music and Theatre:\n[youtube https://www.youtube.com/watch?v=RjlTZuKa7iw?rel=0]\nThis did not quite turn out the way I had intended! In recent work I have been looking to find a way to respond in code to live human improvisations: this session turned into more of an algorave-ish groove built up from mechanical trumpet sounds, over which Anne-Liis worked with the voice. Even so, this was quite succesful. I hope to do more playing with other people along these lines.\n"},{"id":26,"href":"/posts/2018-02-16-livecoding-again/","title":"Livecoding again","section":"Blog","content":" Back at the livecoding again. A couple of weeks ago, a quite succesful workshop for the students on the Interactive Composition module at the Royal Conservatoire of Scotland. Coming up: a couple of things. In March there is going to be another long-form online algorave that I\u0026rsquo;ll be contributing a half-hour set to, Friday 16th at 1330 GMT. In April the METRIC Intensive III at the RCS sees staff and students converge on Glasgow for a week of improvisation: again, as well as leading some gamelan improvisation, expect to be SuperColliding as well.\nBelow, a more-or-less unedited trial run of some new stuff tonight: specifically, a collection of samples made purely from mechanical sounds of my trumpet, close-miked: springs, valve noise, slide pops and so forth.\nhttps://youtu.be/7Yud8TjJMP0\n"},{"id":27,"href":"/posts/2017-07-14-giving-a-workshop-in-jakarta/","title":"Giving a workshop in Jakarta","section":"Blog","content":"My institution, The Royal Conservatoire of Glasgow, have sent me on a trip to make connections with a number of potential partners in Indonesia, including the UPH Conservatory of Music, the Jakarta Institute of Arts (IKJ), and Institut Seni Indonesia Surakarta (ISI Solo). I\u0026rsquo;ll also be visiting Singapore to see Setan Jawa, and talk to the producers about bringing this to Glasgow for a Festival of Gamelan and the Moving Image that we are planning here for September.\nHere\u0026rsquo;s the poster for a workshop I\u0026rsquo;ll be giving at UPH, that will take in a livecoding demo and a performance of Steadily-Stop! alongside an analysis of Antichthon.\n"},{"id":28,"href":"/posts/2017-05-27-merapisuccess/","title":"Ubuntu Studio, SuperCollider, Dell Inspirion 11 3000 - success!","section":"Blog","content":"Having a very positive experience at the moment with Ubuntu Studio 17.04 running SuperCollider 3.8.0 on a £150 refurb 11\u0026quot; Dell Inspiron. Apart from an initial UEFI glitch with getting it to boot, Ubuntu Studio installed easily and works seamlessly so far. The SuperCollider install was made simple by this script install_supercollider_sc3plugins_buntu.sh from @theseansco – thanks Sean! When it came to actually booting SuperCollider, I did not even need to mess around with Jack or any other at all, everything on the audio side seems to just work. Now to push it a little harder…\n"},{"id":29,"href":"/posts/2017-03-08-getting-ready-to-be-five-four/","title":"Getting ready to be five (/four)","section":"Blog","content":"Next Friday I’m going to to be taking part in a 24 hour online algorave event wearefive to celebrate five years of the algorave movement. By accident or design I’m on back to back with coï¿¥ï¾¡pt (aka Sean Cotterill) who is one of only a couple of us livecoding in pure SuperCollider, rather than the by-now overwelmingly popular TidalCycles.\nSean has been putting together an interesting set of pages on his approach to livecoding in SC, particularly on the things that need to be set up beforehand. I’ve evolved some similar ideas myself, perhaps little a less organised and more hacky. For interest, I’ve put my current setup files with comments on sccode.org and also a wee example of the kind of code I use.\nAdmittedly, some of this won’t make sense without the particular arrangement of samples and loops that I use. I’ve recently hit upon the idea of using an array of 32 different drum samples organised roughly in the following pattern:\n00 a bass drum sound 01 hi hat 02 a snare 03 a different hi hat (or other hit) 04 a different bass drum sound … etc\nThat way, I can make a basic un-ta-ka-ta beat just by stepping through all 32, or segments thereof:\nPseq(~arrayOfHits, inf) Pseq(~arrayOfHits[4..7], inf)\nI’ve also discovered some really quite good longer patterns with this layout, using Pslide:\nPslide(~arrayOfHits,inf,4,3)\nGuess we\u0026rsquo;ll see how all of this sounds at the rather unravy time of 0800 GMT next Friday!\n"},{"id":30,"href":"/posts/2017-01-03-recent-livecoding-in-supercollider/","title":"Recent livecoding in SuperCollider","section":"Blog","content":"Over the winter break I\u0026rsquo;ve been spending some time working on my livecoding/algorave setup in SuperCollider. Here\u0026rsquo;s a quick practice run, this is how things are going at the moment.\nhttps://youtu.be/nk58NBtMFvE\nThe most recent idea here is the \\warp synth, a granulator slowly reading through a choice of soundfiles. In this particular run, I think the .choose threw up a fragment of a Stokowski Bach transcription https://archive.org/details/J.S.BACH-OrchestralTranscriptions-NEWTRANSFER and perhaps a bit of the theme tune from The IT Crowd as well. A nice background wash of sound behind the rhythmic stuff. For the latter, the samples in the first half of the video are various from here http://machines.hyperreal.org/manufacturers/ and in the second half of the run, after I exectue ~changesamples, from here http://theremin.music.uiowa.edu/MIS.html and here http://www.philharmonia.co.uk/explore/sound_samples.\nThe synths I\u0026rsquo;m using and my initialisation file is up on GitHub at https://github.com/tedthetrumpet/supercollider.\n"},{"id":31,"href":"/posts/2016-10-06-rave-the-space/","title":"Rave the Space","section":"Blog","content":"Last night I gave a performance called \u0026lsquo;Rave the Space\u0026rsquo; at Stereo in Glasgow, part of a series of events called INTER run by Iain Findlay-Walsh \u0026lsquo;creating a focused, public listening context for deep experiments in / with sound\u0026rsquo;.\nMy proposal was to \u0026lsquo;perform the soundscape of the venue through the medium of livecoding\u0026rsquo;. What I did was to visit the venue the day before, at a quiet time, and make some recordings – a fairly typical basement club/rock venue, so I was able to wander onstage, through dressing rooms, behind the bar, into the toilets etc, all the while recording both the ambience and, in some cases, tapping or hitting objects of particular interest – there was a group of CO2 cylinders that were particularly nice.\nOn the morning of the event, I roughly levelled these recordings, discarded uninteresting ones, cut out handling noise, mobile phone interference, and initial and terminal clicks from the recorder. This left me with nine recordings, each about a minute long.\nI decided to challenge myself by doing as little rehearsal for the performance as possible. I had one synth precoded, a slicing sampler. All this does is to take an audio file and play back one of n slices: in the case of these roughly 60 second long files, I used n=64. On previous occasions when I\u0026rsquo;ve done livecoding/algorave with found sounds, I\u0026rsquo;ve gone through the source audio files carefully in Audacity, looking for particular short sounds that I can then isolate and shape into something resembling a drum hit, then performed with those sounds in place of drum sounds.\nThe slicing approach used here is deliberately less controlled: it\u0026rsquo;s a matter of luck what sound falls where as the point at which the file is sliced is quite arbitrary, perhaps falling just on ambience, or half-way through a percussive noise.\nThe performance was only to be ten minutes: which is not a lot on my timescale of livecoding in SuperCollider! I decided to start with a blank screen: in retrospect, I could have got to better musical gestures faster if I\u0026rsquo;d had maybe ten or a dozen lines precoded. Nevertheless, in this sit-down and concentrate atmosphere, the blank-page start was quite intruiging for the audience, I think.\nThe performance mostly went well, although there was one of those moments where I had what looked like a correctly typed line that evaluated correctly, that did not seem to be doing anything! I still can\u0026rsquo;t figure out what I was doing wrong.\nI\u0026rsquo;m pleased with this idea and intend to repeat it, particuarly the site-specific approach to gathering sounds.\nHere\u0026rsquo;s the code, not much to see here:\n(//setup s.waitForBoot{}; SynthDef(\\sl, { |out, gate=1, buf, sig, slices=16, slice=0, freq = 261.6255653006, amp=0.1| var myenv, env, start, len, basefreq = 60.midicps, rate; rate = freq / basefreq; len = BufFrames.kr(buf); start = (len / slices * slice); myenv = Env.asr(attackTime: 0.01, sustainLevel: 1, releaseTime: 0.1); sig = PlayBuf.ar(2, buf, BufRateScale.kr(buf) * rate, startPos: start); env = EnvGen.kr(myenv, gate, doneAction: 2); Out.ar(out, sig * env * amp) }).add; t = TempoClock(140/60).permanent_(true); u = TempoClock(140/60 * 2/3).permanent_(true); Pbindef.defaultQuant_(4); Pdefn.defaultQuant_(4); ) ( ~paths = [ \u0026quot;/Users/jsimon/Music/SuperCollider Recordings/stereoglasgow/bar.aiff\u0026quot;, // 0 \u0026quot;/Users/jsimon/Music/SuperCollider Recordings/stereoglasgow/c02ambience.aiff\u0026quot;, // 1 \u0026quot;/Users/jsimon/Music/SuperCollider Recordings/stereoglasgow/cafe.aiff\u0026quot;, // 2 \u0026quot;/Users/jsimon/Music/SuperCollider Recordings/stereoglasgow/co2.aiff\u0026quot;, // 3 \u0026quot;/Users/jsimon/Music/SuperCollider Recordings/stereoglasgow/corner.aiff\u0026quot;, // 4 \u0026quot;/Users/jsimon/Music/SuperCollider Recordings/stereoglasgow/lane.aiff\u0026quot;, // 5 \u0026quot;/Users/jsimon/Music/SuperCollider Recordings/stereoglasgow/seatingbank.aiff\u0026quot;, // 5 \u0026quot;/Users/jsimon/Music/SuperCollider Recordings/stereoglasgow/space.aiff\u0026quot;, // 6 \u0026quot;/Users/jsimon/Music/SuperCollider Recordings/stereoglasgow/stage.aiff\u0026quot;, // 7 \u0026quot;/Users/jsimon/Music/SuperCollider Recordings/stereoglasgow/stairs1.aiff\u0026quot;, // 8 \u0026quot;/Users/jsimon/Music/SuperCollider Recordings/stereoglasgow/stairs2.aiff\u0026quot; // 9 ] ) ~thebuf = Buffer.read(s, ~paths[7]); ~thebuf.play // Pbindef(\\x, \\instrument, \\sl, \\buf, ~thebuf, \\slices, 64) Pbindef(\\x).play(t) Pbindef(\\x, \\slice, 0) Pbindef(\\x, \\slice, 64.rand) Pbindef(\\x, \\slice, Pwhite(0,63,inf)) Pbindef(\\x, \\legato, 1/4) Pbindef(\\x, \\dur, 1/4) Pbindef(\\x, \\note, Pwhite(0,12,inf)) // Pbindef(\\y, \\instrument, \\sl, \\buf, ~thebuf, \\slices, 64) Pbindef(\\y).play(u) Pbindef(\\y, \\slice, 0) Pbindef(\\y, \\slice, 64.rand) Pbindef(\\y, \\legato, 4) Pbindef(\\y, \\dur, 1/2) Pbindef(\\y, \\note, Pwhite(-12,12,inf)) t.sched(t.timeToNextBeat(4), {u.sync(120/60, 10)});\n"},{"id":32,"href":"/posts/2016-08-22-the-next-station-if-only-i-had/","title":"The Next Station – ‘if only I had’","section":"Blog","content":"Tomorrow sees the launch of The Next Station, a project by Cities and Memory to reimagine the sounds of the London Underground. My contribution to this project is an audio work called if only I had, constructed entirely from a 3'42 recording of a train arriving and departing from Pimlico station.\nThe title is taken from Spike Milligan’s ‘Adolf Hitler: My Part in his Downfall’:\n‘Edgington and I promenaded the decks. Harry stopped: “If only I had a tube.” “Why?” “It’s quicker by tube.”\n… an inconsequential pun that has, for some reason, always stuck in mind!\nI made this piece as a personal study into the possibility of using livecoding techniques in SuperCollider to develop a fixed piece. In recent months I have been very active in exploring coding in this way, particularly in the context of algorave: if only I had leverages these techinques. Here’s some of the code I used, with explanation:\n( s.waitForBoot{ Pdef.all.clear; Pbindef.defaultQuant = 4; t = TempoClock.new.tempo_(120/60).permanent_(true); ~path = \u0026quot;/Users/jsimon/Music/SuperCollider Recordings/pimlicoloops/\u0026quot;;\nThis is a remnant of what turned out to be a bit of a false start to the project. My initial idea was to look through the file for shortish sections, in the region of 2-3 seconds long that, when looped, had some sort of rhythmic interest. This was done offline, using Audacity. I thought it might be interesting to develop the piece by using these fragments almost in the manner of drum loops, and wrote some code to juxatpose them in various ways at different tempi. This didn\u0026rsquo;t really produce anything very effective however: the material is rather dense and noisy, and when looped together the rhythmic interested was lost in broadband mush of sound.\nInstead, I revisited a synth from an earlier project that slices a buffer into 16 pieces for playback:\n~bufs = (~path ++ \u0026quot;*.aiff\u0026quot;).pathMatch.collect({ |i| Buffer.read(s, i)}); SynthDef(\\slbuf, { |out, buf, slices=16, slice=16, freq=440, sustain=0.8| var myenv, env, start, len, basefreq = 440, rate, sig, sus; rate = freq / basefreq; len = BufFrames.kr(buf); start = (len / slices * slice); sus = BufDur.kr(buf)/16 * sustain * 1.1; myenv = Env.linen(attackTime: 0.01, sustainTime: sus, releaseTime: 0.1); sig = PlayBuf.ar(2, buf, BufRateScale.kr(buf) * rate, startPos: start, loop: 1); env = EnvGen.kr(myenv, 1, doneAction: 2); Out.ar(out, sig * env) }).add;\nAs well as experimenting with reverb, I also had a delay effect in here at one point. Again, the nature of the already fairly resonant material meant that this was not that useful. In the end, I only used the reverb at the very end of the piece as a closing gesture.\n~rbus = Bus.audio(s, 2); SynthDef(\\verb, {|out = 0, room = 1, mix = 1| var sig = FreeVerb.ar(In.ar(~rbus, 2), room:room, mix:mix); Out.ar(out, sig) }).add; s.sync; Synth(\\verb);\nAt some point in developing the project, it occured to me to try playing together the sliced material with the orignal file. This seemed to effective, and gave me a clear trajectory for the work: I decided that the finished piece would be the same pop-song length as the original recording. In experimenting with this approach – playing sliced loops in SC at the same time as playing back the whole file in Audacity – I found myself gently fading the original in and out. This is modelled in the synth below: I used an explicit random seed together with interpolated low frequency noise to produce a replicable gesture:\n~file = \u0026quot;/Users/jsimon/Documents/ Simon's music/pimlico the next station/Pimlico 140516.wav\u0026quot;; ~pimbuf = Buffer.read(s, ~file); s.sync; SynthDef(\\pim, { |out=0, start=0, amp = 1| var sig, startframe, env; startframe = start * 44100; RandSeed.ir(1,0); env = EnvGen.kr(Env.linen(sustainTime: ~pimbuf.duration - 9, releaseTime:9)); sig = PlayBuf.ar(2, ~pimbuf, startPos:startframe, doneAction:2) * LFNoise1.kr(1/5).range(0.05, 1.0); Out.ar(out, sig * amp * env); }).add;\nThere was a nice moment in the original where the accelerating electronic motors of the departing train created a seried of overlapping upward glissandi, sounding very like Shepard tones, or rather, the sliding Risset variation. Looking to enhance this gesture, I tried a couple of my own hacks before giving up and turning to a nice class from Alberto de Campo’s adclib:\n~shep = { var slope = Line.kr(0.1, 0.2, 60); var shift = Line.kr(-1,2,60); var b = ~bufs[8]; var intvs, amps; var env = EnvGen.kr(Env.linen(sustainTime:53, releaseTime:7),1,doneAction:2); #intvs, amps = Shepard.kr(5, slope, 12, shift); (PlayBuf.ar(b.numChannels, b, intvs.midiratio, loop: 1, startPos:3*44100) * amps).sum * 0.2 }; s.sync;\nAll of the above is essentially setup material. The gist of the composition was in iterative experimentation with Pbindefs, as can be seen below: trying out different slicing patterns and durations, working with the various segments I\u0026rsquo;d prepared beforehand in Audacity.\nPbindef(\\a, \\instrument, \\slbuf, \\slice, Pseq((1..8).pyramid(1), 1), \\dur, 1/2, \\buf, ~bufs[1], \\note, 0); Pbindef(\\b, \\instrument, \\slbuf, \\slice, Pser((8..15).pyramid(1), 32), \\dur, 1/4, \\buf, ~bufs[1], \\note, 0); Pbindef(\\c, \\instrument, \\slbuf, \\slice, Pser((2..5).pyramid(1), 32), \\dur, 1/4, \\buf, ~bufs[0], \\note, 0); Pbindef(\\d, \\instrument, \\slbuf, \\slice, Pseq((1..8).pyramid(1), 1), \\dur, 1/4, \\buf, ~bufs[3], \\note, 0); Pbindef(\\e, \\instrument, \\slbuf, \\slice, Pseq((1..8).pyramid(1), 1), \\dur, 1/4, \\buf, ~bufs[3], \\note, 12); Pbindef(\\f, \\instrument, \\slbuf, \\slice, Pseq((1..8).pyramid(1), 1), \\dur, 1/4, \\buf, ~bufs[3], \\note, [-12,12,24,36]); Pbindef(\\g, \\instrument, \\slbuf, \\slice, Pseq((1..8).pyramid(1), 1), \\dur, 1/4.5, \\buf, ~bufs[3], \\note, [12,24,36]); Pbindef(\\h, \\instrument, \\slbuf, \\slice, Pseq((1..8).pyramid(1), 1), \\dur, 1/5, \\buf, ~bufs[3], \\note, [-12,12,24,36]); Pbindef(\\i, \\instrument, \\slbuf, \\slice, Pseq((1..8).pyramid(12), 1), \\dur, 1/6, \\buf, ~bufs[3], \\note, [-24,-12,12,24,36]); Pbindef(\\j, \\instrument, \\slbuf, \\slice, Pseq((1..8).pyramid(1), 1), \\dur, 1/7, \\buf, ~bufs[3], \\note, [-24,-12,12,24,36], \\amp, 0.3); Pdef(\\k, (instrument: \\slbuf, buf: ~bufs[3], slice: 2, note: [-24,-12,12,24,36], amp: 0.5, out:~rbus));\ns.sync; };\nThe final composition was produced by running and recording the code below, which uses the handy Psym as a way to sequence the gestures developed above. The code by this point is entirely deterministic, and would produce the same piece on every run. No further editing was done, apart from normalising in Audacity.\n// start from beginning fork{ Synth(\\pim); 2.wait; Psym(Pseq(\u0026quot;aabaccddeeffghiijk\u0026quot;,1).trace).play(t); (60+14+20).wait; \u0026quot;shep\u0026quot;.postln; ~shep.play; 10.wait; \u0026quot;off again\u0026quot;.postln; Psym(Pseq(\u0026quot;aabaccddeeffghiijk\u0026quot;,1).trace).play(t); }; ) s.prepareForRecord s.record s.stopRecording\nOverall, I\u0026rsquo;m happy with the piece, and glad to have been able to contribute to this very interesting project.\n"},{"id":33,"href":"/posts/2016-08-12-layering-visuals-with-supercollider/","title":"Layering visuals with SuperCollider","section":"Blog","content":"When I was at emfcamp last week, I saw a couple of instances of people layering up visuals with their code. Claudius Maximus had that going with his clive system, SonicPi (and Gibber??) can do it out of the box, and Shelly Knotts had some sort of setup for (I think?) doing it completely within SuperCollider, with the cool idea of a webcam pointing down at her hands on the keyboard.\nAfter a bit of thought, I\u0026rsquo;ve come up with this, just a still for now:\nHow this works: I used a $10 utility called ScreenCaptureSyphon that can amongst other things grab an application window and send it into Syphon. Then, Resolume Arena runs as a Syphon client, which lets me do almost anything including, as in the shot below, pull in the webcam and colorize. Not tried it yet, but Arena exposes its interface to OSC, so should in theory be possible to script visual changes from the SuperCollider IDE.\nA reasonably concinnitous hack, if I say so myself. (MInd you, it\u0026rsquo;s the first thing I\u0026rsquo;ve ever done with my MacBook Air that turns the fan on full blast the whole time!)\n"},{"id":34,"href":"/posts/2016-07-28-getting-my-fingers-burned/","title":"Getting my fingers burned","section":"Blog","content":"Sooner or later, I\u0026rsquo;m going to have to get back to the \u0026lsquo;ol soldering iron:\nI have a plan: to reconstruct the PE Minisonic you can see above, that I made while I was in school. I still have some of the boards…\n"},{"id":35,"href":"/posts/2016-07-13-myscreen/","title":"Here's my screen","section":"Blog","content":"Show us your screens! Ok, well at last maybe I\u0026rsquo;m ready. Here\u0026rsquo;s five minutes or so of me improvising in SuperCollider that\u0026rsquo;s not as embarrassing as some of my other attempts:\nhttps://www.youtube.com/watch?v=Zhprsv_c27o\nThe code is on GitHub if anyone is madly interested.\n"},{"id":36,"href":"/posts/2016-06-27-a-visit-to-copeco/","title":"A visit to CoPeCo","section":"Blog","content":"In my day job in charge of the masters programmes in music at the RCS, I can\u0026rsquo;t help but be interested in innovative new models of postgraduate study. So I was very happy to be able to visit Hamburg this week to observe the CoPeCo programme in action. This is a joint European masters in contemporary performance and composition, where the students study in four different institutions in Estonia, Sweden, France and Germany. The first cohort of the programme are just finishing up at the Hochschule für Musik und Theater, where I was able to attend a concert involving two of the current students, Émilie Girard-Charest (cello) and Sylvain Devaux (oboe), joined by HfMT student Fanis Gioles (percussion).\nSpeaking with them afterwards they were at pains to point out that this concert tonight was perhaps not typical, featuring as it did mostly precomposed music rather than devised, improvised, or collaborative work. For all that, it was a deeply engrossing evening. The first work was Mauricio Kagel\u0026rsquo;s Con Voce, \u0026lsquo;for three mute players\u0026rsquo;. The clue is in the title, with the work opening like a putative companion piece to Cage\u0026rsquo;s 4'33, the three players intense, motionless and… utterly silent. For a very long time! Or, until, as Kagel\u0026rsquo;s direction has it \u0026rsquo;the listeners\u0026rsquo; level of attention is in danger of crumbling\u0026rsquo;. A piece that demands, and was given, great commitment and concentration from the players.\nThe next piece was the premier of a new composition by American composer Heather Stebbins, who it seems had crossed paths with the CoPeCo cohort in Tallin. A great piece, called Crow song, a duet for oboe and cello, working from tentative, unvoiced sounds through to something approaching a melodic shape, and back again. Émilie then gave a performance of Enno Poppe\u0026rsquo;s work for solo cello Herz, all microtones and glisses, beautifully played with an ethereal and un-cello-like tone.\nThe last piece was Dmaathen by Iannis Xenakis, for oboe and percussion. I do enjoy this kind of piece, but admittedly an odd combination: I found my attention drawn more to the percussion writing than to perhaps rather dominated oboe.\nI\u0026rsquo;m looking forward later this week to meeting up with Konstantina Orlandatou who coordinates the CoPeCo programme in Hamburg. Of course, this is a tragically bad time to be even thinking about European collaborations, but… it would be great if we could set up some sort of partnerships along these lines beteen the RCS and comparable institutions on the continent.\n"},{"id":37,"href":"/posts/2016-04-26-first-public-livecode/","title":"First public livecode","section":"Blog","content":"Last night I stumbled into my first public outing of some livecoding I\u0026rsquo;ve been working on in SuperCollider. The context was an improvisation night called In Tandem run by Bruce Wallace at the Academy of Music and Sound in Glasgow. I hadn\u0026rsquo;t intended to play, as I really don\u0026rsquo;t feel I\u0026rsquo;m ready yet, but I had my laptop and cables with me, they had a projector, so…!\nI was jamming along with three other people, on bass, guitar and analog synth. It all went by in a blur, but everyone there seemed to think what I was doing was ok – mostly making grooves out of a random collection of drum samples, but running some algorithmically chosen chords as well.\nThe code is below: this is my screen exactly as I left it at the end of the night, mistakes and all. Although Toplap say \u0026lsquo;show us your screens\u0026rsquo;, they don\u0026rsquo;t say \u0026lsquo;show us your code\u0026rsquo;, but… it seems the right thing to do.\n// the end! // they still going // if you're curious, this is SuperCollider // musci programming language // writing code live is called, er, livecoding // i'm just starting out \u0026quot;/Users/jsimon/Music/SuperCollider Recordings/hitzamples/\u0026quot;.openOS;\n( s.waitForBoot{ Pdef.all.clear; // clear things out ~hitzpath=\u0026quot;/Users/jsimon/Music/SuperCollider Recordings/hitzamples/\u0026quot;; // a folder of samples ~hbufs = (~hitzpath ++ \u0026quot;*.aiff\u0026quot;).pathMatch.collect({ |i| Buffer.read(s, i)}); // samples into an array of buffers t = TempoClock(140/60).permanent_(true); // tempo 140 bpm u = TempoClock(140/60 * 2/3).permanent_(true); // tempo 140 bpm * 2/3 SynthDef(\\bf, {|out=0 buf=0 amp=0.1 freq=261.6255653006| var sig = PlayBuf.ar(2, buf, BufRateScale.kr(buf) * freq/60.midicps, doneAction:2); Out.ar(out, sig * amp) }).add; // this whole chunk defines a synth patch that plays samples }; // Pdef.all.clear; //\u0026quot;/Users/jsimon/Music/SuperCollider Recordings/\u0026quot;.openOS; // t.sync(140/60, 16); ) (instrument: \\bf, \\buf: ~hbufs.choose).play; // play an event using the synth called \\bf // pick a randoms sample from the array (instrument: \\bf, \\buf: ~z).play; ~z = ~hbufs.choose; t.sync(140/60, 32); // gradual tempo changes possible u.sync(140/60 * 2/3, 16); v.sync(140/60 * 5/3, 16); Pbindef(\\x, \\instrument, \\bf, \\buf, ~hbufs.choose).play(t).quant_(4); Pbindef(\\y, \\instrument, \\bf, \\buf, ~hbufs.choose).play(u).quant_(4); Pbindef(\\z, \\instrument, \\bf, \\buf, ~hbufs.choose).play(v).quant_(4); Pbindef(\\z, \\instrument, \\bf, \\buf, ~hbufs.choose).play(v).quant_(4); ~g1 = {~hbufs.choose}!16; // choose sixteen samples at random = one bar full ~g2 = {~hbufs.choose}!16; Pbindef(\\x, \\buf, Pseq(~g1, inf)); // play those sixteen samples chosen Pbindef(\\x, \\buf, Pseq(~g2, inf)); // different sixteen, so, a variation. Pbindef(\\x, \\dur, 0.5); ~d1 = {2.rand/10}!16; ~d2 = {2.0.rand/10}!16; Pbindef(\\x, \\amp, Pseq(~d1, inf)); Pbindef(\\x, \\amp, 0.2); Pbindef(\\x, \\note, Prand((-36..0), inf)); Pbindef(\\x, \\note, Pseq({(-24..0).choose}!16, inf)); // pitch each sample down by random amount Pbindef(\\x, \\note, nil); Pbindef(\\x).resume; Pbindef(\\x).pause; Pbindef(\\z).pause; Pbindef(\\y).resume; // hmm. blx diminished, that's just C major! // was using \\degree instead of \\note, better sounds a bit more like messiaen now :) ~c = {var x = Scale.diminished2.degrees.scramble.keep(4).sort; x.insert(1,(x.removeAt(1)-12))}; // hexMajor thing also works beautifully now! ~c = {var x = Scale.hexMajor6.degrees.scramble.keep(4).sort; x.insert(1,(x.removeAt(1)-12))}; ``// next question might be changing \\note, \\dur and \\root in a coordinated way ( Pbindef(\\k, \\note, Pstutter(Prand([5,7,9,11,13]*2, inf), Pfunc(~c)), \\dur, 0.5, \\root, 3, // best option for feeling of key change \\amp, Prand((2..5)/70,inf) ).play(t); ) Pbindef(\\k).pause; Pbindef(\\k).pause;\n"},{"id":38,"href":"/posts/2016-03-24-recursive-synthesis/","title":"Recursive synthesis","section":"Blog","content":"\nI\u0026rsquo;ve been working for a while with an improvising setup that uses what is sometimes jokingly called \u0026lsquo;recursive synthesis\u0026rsquo; – that is, plugging an effect unit back in to itself and experimenting with the no-input feedback sounds.\nToday I\u0026rsquo;ve had some success with the next step in developing this system. I\u0026rsquo;ve written a SuperCollider patch that allows me to gate and pitchshift the feedback sounds, so that I can begin to find a way to play them musically using a keyboard. Here\u0026rsquo;s the very first run at playing this system: careful, some rather loud and uncontrolled noises here!\n[audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2008/09/recursor01demoedit.mp3\"][/audio]\nrecursor01demoedit.mp3\nIn the picture, you can see the work-in-progress setup. There\u0026rsquo;s a cheapo DigiTech RP55 guitar pedal feeding back through a small mixing desk. I\u0026rsquo;m using a swell pedal to contral some of the parameters of the various fx from the DigiTech, particularly sweeping the pitch of the \u0026lsquo;whammy\u0026rsquo; and \u0026lsquo;pitch shift\u0026rsquo; functions, set up in various presets. The mixing desk is not entirely necessary, but the tone controls are useful to have in the feedback loop.\nBelow is the code for the SuperCollider patch. As always, my thanks to the developers of this software, and all the help received from the community on the mailing list. ( fork{ ~velbus = Bus.control.set(1); // not using yet s.sync; SynthDef(\\pitchin, { | midinote = 60, gate = 1, amp = 0.1 | var in, sig, env, ratio, trans, shift, sel; trans = midinote - 60; in = SoundIn.ar([0,1]); ratio = trans.midiratio; shift = PitchShift.ar(in, pitchRatio: ratio, timeDispersion: 0.1); sel = trans.abs \u0026gt; 0; sig = Select.ar(sel, [in, shift]); env = EnvGen.kr(Env.adsr, gate, doneAction: 2); Out.ar(0, sig * env * amp * 37) // compensate for quiet; }).add; }; MIDIClient.init; MIDIIn.connectAll; ~on.free; ~off.free; ~cc1.free; ~notes = Array.newClear(128); // array one slot per MIDI note ~on = MIDIFunc.noteOn({ |veloc, num, chan, src| ~notes[num] = Synth(\\pitchin, [\\midinote, num, \\amp, veloc * 0.2/127]); }); ~off = MIDIFunc.noteOff({ |veloc, num, chan, src| ~notes[num].release; }); ~cc1 = MIDIFunc.cc({ |val| val.postln; ~velbus.set(val/127*4); }, 1, 0 ); // cc1 on channel 0 = midi channel 1, not using yet )\n"},{"id":39,"href":"/posts/2016-03-18-patchin-at-the-hague/","title":"Patchin' at the Hague","section":"Blog","content":"I\u0026rsquo;ve been at the Koninklijk Conservatorium in Den Haag for the last couple of days, working with a group of academics from all over Europe on the METRIC project – \u0026lsquo;Modernizing European Higher Music Education through Improvisation\u0026rsquo;. (If anyone can tell me in which language that acronym works, I\u0026rsquo;d love to know!)\nWhile I\u0026rsquo;m here, I\u0026rsquo;ve been amusing myself with some work on a simple SuperCollider patch to pitchshift live audio, that I intend to use as part of my own improvisational practice. Particularly tickled to be able to say in future that I \u0026lsquo;worked on this patch at the Institute of Sonology in The Hague\u0026rsquo;, which is strictly speaking… more or less true!\nAlso brings fond memories of another piece of software associated with this institution, ACToolbox, that I used quite extensively in the past, although not so much now.\nLet\u0026rsquo;s hear it for koncon!\nHere\u0026rsquo;s some test code, part of a larger project: // Institute of Sonology, Den Haag, 18 Mar 2016 :) ( SynthDef(\\pitchin, { | trans = 0, gate = 1 | var sig, env, ratio; sig = SoundIn.ar([0,1]); ratio = trans.midiratio; sig = PitchShift.ar(sig, pitchRatio: ratio, timeDispersion: 0.1); env = EnvGen.kr(Env.adsr, gate, doneAction: 2); Out.ar(0, sig * env); }).add; ) x = Synth(\\pitchin); x.set(\\trans, 12); // can sound a bit comby, try timeDispersion about half grainsize x.set(\\trans, -12); x.set(\\trans, 7); x.set(\\trans, -7); x.free;\n"},{"id":40,"href":"/posts/2016-03-14-gamelan-composers-forum/","title":"Gamelan Composers Forum","section":"Blog","content":"Yesterday I was in London with the Gamelan Composer\u0026rsquo;s Forum, an occasional collective brought together by Aris Daryono and Rob Campion to share approaches to writing for the gamelan. This particular event the series is entitled \u0026lsquo;The Intimate Gamelan\u0026rsquo;, and features three pieces written for a gadhon-size ensemble, performing in a private house in South London.\nThere were three new pieces. \u0026lsquo;Sang Empu\u0026rsquo; (\u0026lsquo;The Maestro\u0026rsquo;) was Aris\u0026rsquo; piece scored for cello and ciblon, the cello part being taken by Alice Jones. Aris explains that this piece draws both on the cello tradition within kroncong, where the cello imitates the kendhang, and on the ciblon drummming for palaran.\nRob contributed another piece involving Alice on the cello, \u0026lsquo;New Moon\u0026rsquo;. This featured Rob playing the slenthem with two beaters, like a giant gender: I rather like imagining the cello in this piece as a giant rebab!\nMy own piece was a one-off assemblage of two of my \u0026lsquo;openings\u0026rsquo;, flexible bits of bits of material that I reuse in different ways for different performing occasions. The first part was based on an idea entitled \u0026lsquo;fibblestix\u0026rsquo;, an accellerating series of percussive clicks that eventually prompt a response form the gender. The second part of \u0026lsquo;Two Openings\u0026rsquo; – as the overall piece is called – is \u0026lsquo;Adrift \u0026amp; Afloat\u0026rsquo; adapted for one pelog and one slendro gender. I\u0026rsquo;m very happy indeed with the way Rob and Aris approached this piece, very thoroughly prepared, and sounding very convincing indeed the intimate setting of a private house.\nA fascinating evening: I\u0026rsquo;m glad I made the effort to get down to London to take part.\n"},{"id":41,"href":"/posts/2016-01-29-ball-of-sardines-red-note-noisy-nights/","title":"Ball of Sardines @ Red Note ‘Noisy Nights’","section":"Blog","content":"\nJust for fun, I did an arrangement of Ball of Sardines for one of Red Note\u0026rsquo;s ‘Noisy Nights’: flute violin, trombone, and the conductor playing kethuk. (This is instead of the piece I was going to write, a masterpiece of algorithmic pointilism to be entitled ‘Moment of Indecision’. I may finish that one day…)\nMonday 1 February 2000-2200 – Free Summerhall 1 Summerhall Place Edinburgh - EH9 1QH\n"},{"id":42,"href":"/posts/2015-12-31-working-on-new-music-for-gamelan/","title":"Working on new music for gamelan","section":"Blog","content":"Over the winter break, I\u0026rsquo;ve been working on some new music for gamelan. Following on from Naga Mas\u0026rsquo; rather spectacular success with our gamelan-in-outer-space piece Gamelan Untethered, we have plans to do something along the same lines, but this time on an underwater theme. Below is a midi demo of something I\u0026rsquo;m working on for the group: a sort of sampak/kebyar fusion piece, pulling together some of the livelier ideas from the Javanese traditions with a Balinese-inspired melody.\n[soundcloud url=\u0026ldquo;https://api.soundcloud.com/tracks/239855894\" params=\u0026ldquo;auto_play=false\u0026amp;hide_related=false\u0026amp;show_comments=true\u0026amp;show_user=true\u0026amp;show_reposts=false\u0026amp;visual=true\u0026rdquo; width=\u0026ldquo;100%\u0026rdquo; height=\u0026ldquo;150\u0026rdquo; iframe=\u0026ldquo;true\u0026rdquo; /]\nThis may prove a little tricky to play!\n"},{"id":43,"href":"/posts/2014-07-06-live-coding-and-the-body/","title":"Live Coding and the Body","section":"Blog","content":"I\u0026rsquo;ve just spent a very stimulating weekend, combining an algorave in Brighton with the Live Coding and the Body symposium at Sussex University. A packed weekend: I didn\u0026rsquo;t keep notes of exactly who and what and when, so this is a rather chaotic reflection!\nThe algorave was in a clubby sort of room above a pub. Code from each performer\u0026rsquo;s laptop was projected on a black behind them, while some livecoded visuals in IBNIZ were projected on an adjacent wall. A good atmosphere, although I found the gig sometimes painfully loud, especially with those very forward and raw sounds which you sometimes get from coded synths.\nThe first set I caught was Chris Kiefer, working in SuperCollider (the old, pre-IDE version, looked like). This was excellent: very approachable danceable grooves, with a nice line in slowly changing fx. After that, Aneurin Barker Snook did a set in Tidal. It\u0026rsquo;s the first time I\u0026rsquo;ve seen this Haskell-based tool: to me it seemed quite firmly targetted at algorave, rather than a more general approach to coding music performance. A very harsh set, if I remember correctly, but still musical and interesting.\nFrom this point on, my memory is a little blurred. A very abstract and glitchy set from Norah Lorway: not sure what tool she was using as she did not have time to plug into the projector. Also Charlie Roberts playing his own web-based Gibber language, with a nice line in livecoding the ascii text. Oh, and… Mico Rex – bonkers! In a good way: cardboard boxes, SC code, and exuberant singing.\nThe symposium programme turned out to be a little different from the published one: once again, this will be a bit disorganised as I didn\u0026rsquo;t keep accurate notes. A fascinating range of disciplines and interests in the room, including people working in music, fine art, architecture, dance, analog synthesis, social anthropology, and more. Some of the highlights I recall:\nMarije Baalman gave a very, very cool performance of her piece \u0026lsquo;Wezen\u0026rsquo;, a tour-de-force of live SuperCollider code combined with sensor gloves. Renick Bell\u0026rsquo;s presentation sparked off quite a lively debate, bringing to the table his reinterpretation of the pragmatic philosophy of John Dewey. Some deep questioning of his philosophical approaches ensued, led by David Berry in particular. David Ogborn gave us two treats. The first was a multi-layered coding piece, with Pbindef\u0026rsquo;s in SuperCollider being generated by another piece of SC code and programatically \u0026rsquo;typed\u0026rsquo; onto the screen, leaving David free to add in a solo part on electric guitar. On day two, he talked us through a stimulating range of people, ideas and references as a follow up. Andrew R Brown talking about a spectrum of approaches to controlling algorithms, from text to gestural controllers, and points in between: also a nice demonstration of his own rig, using impromputu combined with a simple bank of sliders and switches on an iPad mini. Alex McLean shared some of his work in collaboration with dancer Kate Sicchio. Andrew Duff gave a lively and fun talk/demo on the modular synth scene, liberally illustrated by humorous gifs from the Muff Wiggler forums. A lot of gear porn here, really, including mention of the Pismo: ok, that\u0026rsquo;s it, I\u0026rsquo;m hanging on to mine, one day I\u0026rsquo;ll get it up and running again! Cecile Chevalier drew some comparisons between livecoding and the work of Jackson Pollock, although as we unpicked that, perhaps a slightly problematic parallel… Overall, a very pleasant long weekend in the very pleasant seaside town of Brighton. The Sussex University campus was very comfortable, as was the wonderful Dutch bike I hired from Amsterdammers.\nOther things I learned about:\nthe empyre mailing list http://openendedgroup.com/field/ IOhannes Zmoelnig\u0026rsquo;s attempts to livecode Pd in Braille Marije\u0026rsquo;s piece \u0026lsquo;Code Live Code Live\u0026rsquo;, livecoding the sound of typing Final braindump, below an archive of all the #lcatb tweets (some of the attributions here probably wrong, collected this list in a rather hacky way…):\nGreat response - mod syths @yaxu suggests that we don\u0026rsquo;t react against the digital but instead software, which is \u0026lsquo;generally awful\u0026rsquo; #lcatb berrydm 12:18pm via Twitter for iPhone\nAndrew Duff showing his own personal \u0026ldquo;Orac\u0026rdquo; and modular synths at Live Coding and the Body #lcatb http://pic.twitter.com/RTq06khkYC thormagnusson Jul 05, 2:06pm via iOS\nHere @allthesixes666 presents a graph that should resonate with many computer musicians\u0026rsquo; experience #lcatb http://pic.twitter.com/qE3aFcqBYT Retweeted by _sshaw and 4 others thormagnusson 11:52am via iOS\n#lcatb Afternoon kicking-off with @berrydm \u0026amp; Nick Rothwell coding as collaborative fist class discipline http://pic.twitter.com/DtGJ7tB68v Retweeted by musicSussex and 5 others thormagnusson 12:08pm via iOS\nLive coding the modular synths #lcatb http://pic.twitter.com/msuYv3o5vr Retweeted by musicSussex and 3 others thormagnusson 12:08pm via iOS\n@ad_tpim Does \u0026rsquo;lowres\u0026rsquo; modular syth demo at #lcatb symposium @SussexUni http://instagram.com/p/qG3rrrKD16/ thormagnusson 11:52am via iOS\nAndrew Duff\u0026rsquo;s great modular synth setup at Live Coding and the Body seminar. Cool! #lcatb http://pic.twitter.com/5e7M3Bk7Wp pauwly 12:01pm via Twitter for Android\nAndrew Duff @allthesixes666 blames his modular addiction on close friend @RussellHaswell #lcatb http://pic.twitter.com/e14heqdtKE thormagnusson 11:52am via iOS\n#lcatb Pismo, very nice, I\u0026rsquo;ve already got one :) pauwly 11:43am via Twitter for Android\nGreat talk by David Ogborn d0kt0r0.net #Livecoding #acousmonium #spacialisation #emodiment #lcatb http://pic.twitter.com/CM9eLPhBFi tedthetrumpet 11:35am via Hootsuite\nhttp://ow.ly/i/68GoK David Ogborn offering some leads to follow #lcatb renick 11:21am via Twitter for Android\n@berrydm wish an AI were running traffic on the way to #lcatb today\u0026hellip; Show Conversation pauwly 11:00am via Twitter for Android\nOpen questions about control through gesticulation and code in live performance #lcatb http://pic.twitter.com/LuQZVgmsL9 lukechurch 10:55am via TweetDeck\nWatching Andrew Brown merge gestural control via an iPad and a text programming language at #lcatb, we should add this to #DynamoBIM soon. tedthetrumpet 10:51am via Hootsuite\n#lcatb Andrew R Brown reflecting on the balance between textual and gestural control berrydm 10:44am via Twitter for iPhone\nDay 2- Live Coding and the Body on a Sunday (!?!) with Andrew Brown (gestural controllers \u0026amp; code description) #lcatb http://pic.twitter.com/AuCgcdjeNC TanyaMGoncalves 10:43am via Twitter for Android\n#LCATB - sad that today is my last day of confrences #untilnexttime http://pic.twitter.com/E4TsL7KpoY tedthetrumpet 9:28am via Hootsuite\nDay 2 of Livecoding and the Body starts soon: great to be here, meeting interesting people, and learning stuff http://livecodenetwork.org/body/ #lcatb TanyaMGoncalves Jul 05, 3:47pm via Twitter for Android\n@d0kt0r0 performing live #LCATB http://pic.twitter.com/qRegzVZdhh Retweeted by d0kt0r0 and 1 others yaxu 12:31am via Twitter Web Client\nSuper discussions at the live coding at the body symposium, check out the #LCATB hashtag. Retweeted by supersg559 yaxu 12:31am via Twitter Web Client\nSoviet synthesizer bridged occultism and electronic music — will be of interest to #lcatb http://boingboing.net/2012/06/27/syn… thormagnusson Jul 05, 2:06pm via iOS\n#lcatb Afternoon kicking-off with @berrydm \u0026amp; Nick Rothwell coding as collaborative fist class discipline http://pic.twitter.com/DtGJ7tB68v Retweeted by giovamusic and 5 others TanyaMGoncalves Jul 05, 5:10pm via Twitter for Android\n@yaxu @yaxuprime Alex McLean #LCATB http:// pic.twitter.com/k99dG29Rcf shelly_knotts Jul 05, 5:10pm via Twitter Web Client\nnice to have a few controversial comments - referring to live coding as a gendered practice is fairly problematic #lcatb tedthetrumpet Jul 05, 5:04pm via Hootsuite\n#lcatb interesting discussion around livecoding compared with the work of Jackson Pollock cappelnord Jul 05, 4:58pm via Twitter Web Client\n#lcatb people: Thanks for tweeting! kunstwissen Jul 05, 4:36pm via Twitter Web Client\nMicorex ask: why should a live coder be on stage? after presenting some of their practice: hitting buttons, singing, dancing… moving #lcatb Retweeted by sicchio and 1 others danny_bright Jul 05, 4:28pm via Twitter for iPhone\nAwesome - cardboard boxes full of wires and joysticks - surely the best controllers #lcatb http://pic.twitter.com/RbPS0HWbjm Retweeted by livecodenet kunstwissen Jul 05, 4:40pm via Twitter Web Client\n@kunstwissen some responses:challenging context of performance, sharing experience, put emphasis on coding as a cultural practice #lcatb Retweeted by livecodenet kunstwissen Jul 05, 4:36pm via Twitter Web Client\n@d0kt0r0 performs with a multi channel live coding demon which is //not evil #lcatb http://pic.twitter.com/ykZZ2mXne0 Retweeted by tedthetrumpet and 1 others kunstwissen Jul 05, 4:36pm via Twitter Web Client\nA brilliant presentation by @cassieldotcom on code and choreography. #lcatb http://pic.twitter.com/b7gFQNJJN9 Retweeted by livecodenet and 6 others shelly_knotts Jul 05, 2:33pm via Twitter Web Client\nnext symposium: \u0026lsquo;Live Coding and Socks\u0026rsquo;? ;) #lcatb Retweeted by livecodenet pauwly Jul 05, 3:00pm via Twitter for Android\nWe\u0026rsquo;re flying now - forget Deleuze #lcatb Retweeted by livecodenet pauwly Jul 05, 2:39pm via Twitter for Android\nHester Reeve - Why might we choose to use the body live? The audience as witness and not consumer. #lcatb http://pic.twitter.com/J607tF57lE Retweeted by livecodenet and 1 others berrydm Jul 05, 3:46pm via Twitter for iPhone\nNext Marije Baalman live coding a set #lcatb http://marijebaalman.eu http://pic.twitter.com/7bpQtKBNYk Retweeted by livecodenet TanyaMGoncalves Jul 05, 3:47pm via Twitter for Android\n#lcatb David Ogborn performs - #guitar meets #SuperCollider #generative #code http://pic.twitter.com/HYZjf8YTCH Retweeted by livecodenet and 1 others danny_bright Jul 05, 4:15pm via Twitter for iPhone\nLots of interesting people, talks, presentations and performances so far at #lcatb @musicSussex sicchio Jul 05, 3:36pm via Twitter for iPhone\nPerformance #2 Marije Baalman http://marijebaalman.eu - making the code sweat! #lcatb http://pic.twitter.com/HJkM9EtNDO Retweeted by livecodenet and 1 others pauwly Jul 05, 4:09pm via Twitter for Android\n@d0kt0r0 performs with a multi channel live coding demon which is //not evil #lcatb http://pic.twitter.com/ykZZ2mXne0 Retweeted by shelly_knotts and 1 others TanyaMGoncalves Jul 05, 3:47pm via Twitter for Android\n@d0kt0r0 performing live #LCATB http://pic.twitter.com/qRegzVZdhh 2 retweets berrydm Jul 05, 3:46pm via Twitter for iPhone\nDavid Ogborn playing guitar \u0026amp; live coding set - interesting use of live generated code #lcatb d0kt0r0.net http://pic.twitter.com/skVRCI1AcX sicchio Jul 05, 3:36pm via Twitter for iPhone\nTrying to keep up with Live Coding and the Body tweets #lcatb 1 retweets tedthetrumpet Jul 05, 3:31pm via Hootsuite\n#lcatb surrounded by all these coders, I should probably just *ask* someone why my Pbindef won\u0026rsquo;t .play until I .stop it :) thormagnusson Jul 05, 2:06pm via iOS\nHester Reeve - Why might we choose to use the body live? The audience as witness and not consumer. #lcatb http://pic.twitter.com/J607tF57lE Retweeted by berrydm and 1 others pauwly Jul 05, 2:39pm via Twitter for Android\nA brilliant presentation by @cassieldotcom on code and choreography. #lcatb http://pic.twitter.com/b7gFQNJJN9 Retweeted by readywriting and 6 others thormagnusson Jul 05, 2:06pm via iOS\nA very provocative slide #lcatb http://pic.twitter.com/3C86R3jig6 Retweeted by livecodenet TanyaMGoncalves Jul 05, 1:49pm via Twitter for Android\nChats about #livecoding, I\u0026rsquo;m having a little too much fun right now. #LCATB http://pic.twitter.com/bvjctMorDH Retweeted by livecodenet pauwly Jul 05, 1:52pm via Twitter for Android\nHere is the programme for the conference Live Coding and the Body 2014 #lcatb http://livecodenetwork.org/body/ Retweeted by goldsmif and 2 others tedthetrumpet Jul 05, 12:14pm via Hootsuite\n#lcatb Renick Bell is trying to get the body *out* of performance (!?) Retweeted by livecodenet tedthetrumpet Jul 05, 12:14pm via Hootsuite\nNow we have Renick Bell on pragmatic aesthetics ad live coding #lcatb http://renickbell.net/doku.php Retweeted by livecodenet berrydm Jul 05, 11:00am via iOS\nHeideggerian phenomenology might give some useful notions for conceptualisation of live coding practice see http://beingintheworldmovie.com #lcatb Retweeted by livecodenet berrydm Jul 05, 11:54am via Twitter for iPhone\n@livecodenet new discipline love coding? #lcatb Retweeted by livecodenet berrydm Jul 05, 11:48am via Twitter for iPhone\n“@_TheTerminator_: @berrydm I am a cybernetic organism. Living tissue over a metal endoskeleton.” #lcatb Show Conversation kaoskorobase Jul 05, 11:45am via Twitter for iPad\nI warned you.. @_TheTerminator_: @berrydm Skynet became self-aware at 2:14am Eastern time, August 29. #lcatb Show Conversation pauwly Jul 05, 11:38am via Twitter for Android\nNow discussing livecoding blind \u0026amp; connecting machine directly to brain function..its a little after 11am ;D #lcatb http://pic.twitter.com/EH3lbJqNJb Retweeted by livecodenet pauwly Jul 05, 11:38am via Twitter for Android\nSo @thormagnusson outlines his scary brain control live coding ideas. Skynet will soon be here via ixi lang http://ixi-audio.net/ixilang/ #lcatb berrydm Jul 05, 11:24am via Twitter for iPhone\nLive coding and contextual computing - interesting possibilities for new frameworks for creativity and sonic arts #lcatb livecodenet Jul 05, 11:22am via Twitter for Android\nMarije Baalman providing analysis of love coding interaction loop. Wonders about live coding with eyes closed #lcatb http://pic.twitter.com/2AAPW6L6dl thormagnusson Jul 05, 11:01am via Twitter Web Client\nA fantastic group of people have convened in the Creativity Zone at Sussex to discuss Live Coding and the Body #lcatb // @livecodenet Retweeted by livecodenet and 6 others berrydm Jul 05, 11:15am via Twitter for iPhone\nHow obduracy of the computer can be used to feedback electromagnetic waves into music \u0026amp; sound- Laptop Music (Reuss) - v. Cybernetic #lcatb TanyaMGoncalves Jul 05, 11:06am via Twitter for Android\n#LCATB http://pic.twitter.com/VyS5fNmbHm berrydm Jul 05, 11:00am via iOS\nThanks for prompting hashtag @berrydm ;D Here we go, going to be great! #lcatb berrydm Jul 05, 11:03am via Twitter for iPhone\nFirst speaker is Marije Baalman #lcatb http://marijebaalman.eu thormagnusson Jul 05, 11:01am via Twitter Web Client\n\u0026ldquo;Michel [Waisvisz] was only interested in code if he could make it sweat\u0026rdquo; (Sally-Jane Norman) #lcatb tedthetrumpet Jul 05, 11:02am via Hootsuite\n#lcatb so far I\u0026rsquo;ve learned how to pronounce \u0026lsquo;NIME\u0026rsquo; and \u0026lsquo;Gibber\u0026rsquo; tedthetrumpet Jul 05, 11:01am via Hootsuite\nSally Jane Norman introduces the first panel #lcatb http://pic.twitter.com/wlrKhgS6hz Retweeted by thormagnusson berrydm Jul 05, 10:58am via Twitter for iPhone\nWe have a hashtag for the Live Coding and the Body conference #lcatb @SussexUni Retweeted by thormagnusson berrydm Jul 05, 10:59am via Twitter for iPhone\n"},{"id":44,"href":"/posts/2013-06-28-about-why-scotland-why-east-kilbride/","title":"About ‘Why Scotland, Why East Kilbride’","section":"Blog","content":"I’ve been calling myself a ‘composer’ for about twenty years now, starting from when I went back to music college as a trumpet player but got sidetracked into writing music instead of playing it. On my website you’ll find early pieces like ‘Rate-limiting Step’ for cello \u0026amp; harp, or ‘Studies of Nucleate Boiling in Thin Liquid Layers (Part 1)’ for chamber ensemble. This is what people usually think of when I say I’m a ‘composer’: someone who writes contemporary score-based music for classically trained instrumentalists to play.\nYes, I’ve done a lot of that: but over the years it’s come to seem less and less interesting to me. For a number of years now, I’ve been working in a way which is much more akin to devised theatre, or even performance art. For a start, I hardly ever write the music down now, or if I do, it’s just fragments, starting points. By convention, a contemporary classical composer is expected to put everything in the score: the written score is the piece of music. You could post it off to an ensemble anywhere from Albuquerque to Zhytomyr, turn up a week later, and boom, there’s the piece being played.\nOr at least, that’s the theory. But, take the very first work in my catalog, ‘The Knowing of Things Together’. It’s ‘scored’ for didjeridu, three flutes, three trombones, conga drums \u0026amp; two wine bottles (red). Already, there’s a problem: that’s not a standard ensemble! So, actually, no-one is ever going to play this piece, apart from the people I was working with back then. So, really, the music is what the musicians and I actually did on that occasion, rather than anything I might write down.\nFast forward. The piece that’s about to come to fruition, ‘Why Scotland, Why East Kilbride’, started life as a dream. This happens to me a lot: I’m a musician, after all, and I have dreams where I hear a piece of music. Quite often when I wake up I can remember at least some of it: I rush to write it down or even just sing it into my phone before it goes.\nThe piece I heard on this occasion – it was the morning of the 3 June 2012 – seemed to be for… a rock band? Plus a section of orchestral French horns?!?\nMade some notes, forgot about it. Couple of days later, aimlessly surfing around as you do, I stumbled upon this 1972 public information film about East Kilbride. Suddenly a whole chunk of memory descended upon me. I remembered the two different times in my life when I lived in East Kilbride, particularly a period in the eary 80s where I was busy dropping out of an ill-advised science degree at university, listening to a lot of Hawkwind, and teaching myself to play guitar. Suddenly, the dream made sense: I knew what I was listening to, I knew what it was all about.\nAnd the Ted Edwards stuff? A misdirection, perhaps. Edward ‘Teddy’ Edwards is a fictional alter ego of mine. He’s the person I would have liked to have been if I’d been born forty years earlier: he’s Raymond Scott, he’s Daphne Oram, he’s my dad’s golfing buddy who owned a radio shop, he’s Erik Satie. Or maybe he’s a complete unknown: he’s Ziggy Elman, he’s the guy who first came up with the npn-pnp astable multivibrator circuit, he’s some guy who’s into birdwatching.\nHe’s a useful vehicle: someone I can have in my show, someone who might have been in East Kilbride in 1972, might have played in a rock band, might have had a day job as a chemist at the National Engineering Laboratory. Someone who might, after all, be a composer.\nKind of.\n"},{"id":45,"href":"/posts/2013-06-24-electronics-nostalgia/","title":"Electronics nostalgia","section":"Blog","content":"Very happy today. Been working on some electronics for the show. For me as a creator, this is a big part of what Why Scotland, Why East Kilbride is about: exploring my nostalgia for teenage evenings spent with a soldering iron, a cup of coffee, and a Hawkwind album.\nSome pics below: trying to get my SN76477 prototyping station back up and running.\n"},{"id":46,"href":"/posts/2013-06-21-horn-a-tron/","title":"Horn-a-Tron","section":"Blog","content":"Some of the publicity put out for the show has perhaps been unintentionally slightly misleading! I did have a dream of having a French horn section in the show, but that dream has been realised through… technical means :)\nInstead of live players, I\u0026rsquo;ve invented the \u0026lsquo;Horn-a-Tron\u0026rsquo;. This is a Pd patch which plays back midi horn sounds alongside video clips of sixteen horn players – with thanks to Steve Park for the horn vids. I\u0026rsquo;m not going to put up a clip of this working just yet, spoil the effect. But here\u0026rsquo;s the patch:\n"},{"id":47,"href":"/posts/2013-06-17-why-scotland-why-strathclyde-uni/","title":"Why Scotland, Why Strathclyde Uni?","section":"Blog","content":"A couple of interesting connections between the show and the University of Strathclyde. The first is – and I didn\u0026rsquo;t spot this till the other day – it\u0026rsquo;s actually mentioned in the original movie. At around 16 minutes, during the segment where Bruce and Mark visit the National Engineering Laboratory, there\u0026rsquo;s this exchange:\nNEL Employee: We\u0026rsquo;ve got about three hundred and forty engineering graduates and scientific workers here, so we can tackle all sorts of engineering problems. Bruce: Is there any basic research? NEL Employee: Well at the moment it\u0026rsquo;s about twenty percent, I suppose, it used to be more but we\u0026rsquo;re now tackling industrial problems. We have close links with Strathclyde which is one of business leading technical universities.\nThe other connection is of course Dr Steven Ford, who, as well as being one of my bassists, is going to be doing the live chemistry. Steve\u0026rsquo;s day job is as a Research Fellow at Strathclyde\u0026rsquo;s Cancer Research UK Formulation Unit. For the show, he\u0026rsquo;s having fun trying to mock up some outdated (and dangerous!) liquid handling practices, as well as making some interesting chemical smells. As someone who nearly became a scientist myself – I started a BSc at Edinburgh – I\u0026rsquo;m delighted to be able to get this kind of work into the project.\n(In fact, I almost went to Strathclyde myself… I remember going to their open day, and a lot of my friends ended up studying there. And of course, many, many years after that came the Invention Ensemble, which arose out of Strathclyde\u0026rsquo;s wonderful BA in Applied Music course… )\n"},{"id":48,"href":"/posts/2013-06-06-update-on-why-scotland-why-east-kilbride/","title":"Update on 'Why Scotland, Why East Kilbride'","section":"Blog","content":"Exactly a month to go now to \u0026lsquo;Why Scotland, Why East Kilbride\u0026rsquo;, my Cryptic Nights show at the CCA. Today I met with Steve Ford, who, as well as playing bass is going to be doing the live audio chemistry. Here\u0026rsquo;s an example of the kind of thing we won\u0026rsquo;t be doing: Somehow that one never got through the risk assessment :)\n"},{"id":49,"href":"/posts/2013-03-07-first-performance-of-rite-for-four-pianos-and-electronics/","title":"First performance of RITE for four pianos and electronics","section":"Blog","content":"Rather cool to be sharing the bill with \u0026lsquo;Six Pianos\u0026rsquo; tomorrow night. Call me a boring old minimalist, but I still love that piece.\nHere\u0026rsquo;s the lineup:\nMultiple Piano Extravaganza 7.30pm Stevenson Hall, Royal Conservatoire of Scotland £9.50/£6.50\nSteve Reich Six pianos Jonathan Plowright, Alina Horvath, Maraike Breuning, Monika Palsauskaite, Catherine Clark, Donal McHugh\nVera Stanojevic Droplets of Dew for 4 pianos and electronics (World Premiere) Sinae Lee, Graeme McNaught, Fali Pavri and Aaron Shorr\nFree improvisations for multiple pianos, electronics and voice Anto Pett, Anne Liis Poll, Alistair MacDonald and Aaron Shorr\nJ Simon van der Walt RITE for Four Pianos and Electronics (World Premiere) Sinae Lee, Fionnuala Ward, Beth Jerem, Marlon Bordas Gonzalez\n"},{"id":50,"href":"/posts/2013-02-21-more-work-in-progress-on-rite-pics/","title":"More work in progress on RITE – pics","section":"Blog","content":" From the second rehearsal for RITE: pianists Sinae Lee, Fionnuala Ward, Beth Jerem and Marlon Bordas Gonzalez trying out the fx units, and my script for the piece so far.\nRITE for for four performers, four pianos, and four effects units: Friday March 8, 1930, Royal Conservatoire of Scotland. Also featuring works by Steve Reich and Vera Stanojevic, improvisations by Alistair MacDonald, Anto Pett, and Anne-Liis Poll.\n"},{"id":51,"href":"/posts/2013-01-27-quartz-composer-video-sampler-for-wswek/","title":"Quartz Composer video sampler for WSWEK","section":"Blog","content":"Here\u0026rsquo;s a screenshot of something I\u0026rsquo;ve been working on today for \u0026lsquo;Why Scotland, Why East Kilbride\u0026rsquo;:\nRegular readers of this blog (ahem) will recall that this all started with a piece of music I heard in a dream, for a double rock band plus a big squad of french horns. Well, the double rock band is doable, but the french horns were going to be impractical for the gig.\nSo, I\u0026rsquo;m building a sort of video sampler. There will be video clips of each of the four chords the horns play, with four different variations of each chord. Midi notes will then be used to trigger a clip of the correct chord. This would have been easy to do using Jitter in Max… so I had to do it the hard way and try to build it in Quartz Composer!\nI\u0026rsquo;m getting there, ish. The visual tools in QC are amazing, but the program structuring and logic is kind of Turing-machine basic. Like, to combine four numbers I had to use a combination of three OR gates, and to build a toggle switch it\u0026rsquo;s a counter then take the count modulo 2. And it\u0026rsquo;s crashy and buggy, and the documentation is rudimentary. And I\u0026rsquo;m going to have to edit the video super carefully, if the clips aren\u0026rsquo;t exactly 2400ms long then my programming will break.\nBut… it might just work.\n"},{"id":52,"href":"/posts/2013-01-19-first-rehearsal-for-why-scotland-why-east-kilbride/","title":"First rehearsal for 'Why Scotland, Why East Kilbride'","section":"Blog","content":"We\u0026rsquo;ve just had the first rehearsal for \u0026lsquo;Why Scotland, Why East Kilbride\u0026rsquo;, which is a new piece I\u0026rsquo;m putting together for Cryptic Nights, 4 \u0026amp; 5 July of this year. This piece is a fantasy: an reimagination of my own East Kilbride childhood, as expressed through the medium of my alter ego Edward \u0026lsquo;Teddy\u0026rsquo; Edwards, unsung hero of early British electronica.\nThe musical starting point for this piece was a dream I had, where I heard a fragment of music for what seemed to be a double rock band plus an orchestral horn section. Tonight was the first jam session with the band I\u0026rsquo;ve put together. This is made up of people who don\u0026rsquo;t really do this sort of thing! I\u0026rsquo;ve got two ex students of mine, Aimée Laws and Nikki Donaldson (from Edinburgh College and the Conservatoire respectively) on drums and keyboards. My second drummer is legendary percussionst/composer Steve Forman, a colleague of mine from the Conservatoire, while on bass I\u0026rsquo;ve got Steve Ford, who I\u0026rsquo;m also collaborating with on a sci-art sonifiation project. Rounding out tonights lineup was Bill Whitmer, aka williwaw, a great ukulele player, whose solo improvisations to film loops is part of my inspiration for this project.\nI played guitar for tonight, although in the final thing I thing I\u0026rsquo;ll probably be swapping between elecronic noise-makers and a video sampler, which I\u0026rsquo;m going to use to represent the horn players. So, we had four chords and… we jammed.\nInteresting. When I was a teenager, the idea that one day I would play rhythm guitar in a space rock band seemed like some sort of unattainable dream. Now it seems all I need to do is book a rehearsal room and go for it. Musically, it\u0026rsquo;s a ridiculously easy thing to do. However, I do now have some work to do to structure the whole show: in the end, 25 minutes of semi-inept rock jamming just sounds like, er, 25 minutes of semi-inept rock jamming!\nI have some ideas. I\u0026rsquo;ve tried putting the recording of our best jam together with the video, and it\u0026rsquo;s got something going for it. Not going to make that public for now, would spoil the surprise…\n"},{"id":53,"href":"/posts/2012-11-27-work-in-progress-rite/","title":"Work in progress - RITE","section":"Blog","content":"I\u0026rsquo;m working on three pieces of music at the moment. Well, that is, I\u0026rsquo;m supposed to be working on three pieces of music at the moment – today I actually managed to get some work done on two of them, at any rate.\nThe big project I have on the go is Why Scotland, Why East Kilbride, a music theatre piece for Cryptic Nights, CCA Glasgow 4 \u0026amp; 5 July next year. It\u0026rsquo;s for double rock band with video projection, including, I\u0026rsquo;ve just decided today, a \u0026lsquo;digital video mellotron\u0026rsquo;, which I\u0026rsquo;m going to use to deliver the 16 French horn parts needed for the piece. However, the work I\u0026rsquo;ve done on that piece today is boring and administrative…\nMore interestingly, I\u0026rsquo;ve turned this evening to a new work in progress called RITE, for four performers, four pianos, and four effects units. The centenary of the Rite of Spring is coming up next year, and I\u0026rsquo;ve been invited to write a piece, hence the deliberately-dodgy all caps title. To quote my current draft of the programme note:\nThe title of the piece is an acronym: it might also be spelled R.I.T.E. Perhaps it stands for this:\nRecursive Invariant Transform (Electronic) = RITE\nOr possibly:\nRITE is terrible ecronym.\nThe four effects units are going to be used as feeding-back no-input noise-makers, operated by the pianists themselves. I\u0026rsquo;ve spent some happy hours surfing eBay for obsolete fx units and mixers: my latest purchase is a lovely old ART FXR Elite II which you can hear on the clip below. For the pianistic material, I\u0026rsquo;m mulling over those little bits of the piece which have always stuck in my ear, and kind of rewriting them as if from memory. Today I\u0026rsquo;ve been reworking the little scale for two flutes at the very end of the piece, just eighteen notes, which have already generated several minutes of material.\nThis clip is a kind of meditative recomposition of the initial two chords from the \u0026lsquo;Mystic Circles of the Young Girls\u0026rsquo;, combined with recursive fx stuff:\n[audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2008/09/rite_sketch_01.mp3\u0026rdquo;][/audio]\nrite_sketch_01.mp3\n"},{"id":54,"href":"/posts/2012-07-20-sonifying-ir-spectroscopy-data-rhythm/","title":"Sonifying IR spectroscopy data – rhythm","section":"Blog","content":"For today\u0026rsquo;s exciting episode, I\u0026rsquo;m using the simplified spectrum data from glycine to generate a sound, and then looping round the same data to play the sound in a kind of \u0026lsquo;rhythm\u0026rsquo;:\n[sourcecode] ( ~name = \u0026#34;glycine\u0026#34;; ~path = Document.current.dir.asString++\u0026#34;/\u0026#34;++ ~name ++\u0026#34;.csv\u0026#34;; f = CSVFileReader.readInterpret(~path); f = ((f.flop[1] * -1) + 1).normalize; f = (f*100).asInteger; f = f.differentiate.removeEvery([0]).integrate; f = f/100; ~peaksIndices = f.differentiate.sign.findAll([1,-1]); g = Array.fill(f.size, 0); ~peaksIndices.do { |i| g[i] = f[i] }; // Daniel\u0026#39;s line ~amps = g; // [f,~amps].plot(~name, Rect(840,0,600,450)); ~freqs = (36..128).resamp1(f.size).midicps; SynthDef(\\glycine, { | gate=1, amp | var env, sig; sig = Klank.ar(`[~freqs, ~amps, nil], PinkNoise.ar(amp/100)); env = EnvGen.kr(Env.perc, gate, doneAction: 2); Out.ar(0, Pan2.ar(sig, 0, env)) }).add; Pbind(\t\\instrument, \\glycine, \\amp, Pseq(~amps, 4).collect { |amp| if(amp \u0026amp;gt; 0) {amp} {Rest}}, \\dur, 0.02, ).play; ) [/sourcecode] [audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2008/09/glycinerhythm.mp3\"][/audio]\nglycinerhythm.mp3\nIn other news, my collaborator Steve has been having Ideas. Watch this space.\n"},{"id":55,"href":"/posts/2012-07-19-sonifying-ir-spectroscopy-data-finding-peaks/","title":"Sonifying IR spectroscopy data - finding peaks","section":"Blog","content":" Emperor Joseph II: Well, I mean occasionally it seems to have, how shall one say? [he stops in difficulty; turning to Orsini-Rosenberg] How shall one say, Director? Orsini-Rosenberg: Too many notes, Your Majesty? Emperor Joseph II: [to Mozart] Exactly. Very well put. Too many notes. From Amadeus (1984)\nIt occured to me after a while that my previous attempts at dealing with these sets of data were running into a \u0026rsquo;too many notes\u0026rsquo; problem: 784 resonators at once is always likely to sound like noise! What one would like to be able to do would be to focus in on the visible \u0026lsquo;peaks\u0026rsquo;:\nThis is something a human can do quite intuitively: in fact, I seem to dimly remember that, many years ago, when I worked with HPLC (High Performance Liquid Chromatography) data at Schweppes, there was a pencil and paper method we used to estimate the height and width of a peak, and thus determine the concentration of a compound by calculating the area under the graph.\nA little research into the problem of doing this algorithmically rapidly took me far out of my mathematical depth:\nChao Yang, Zengyou He, Weichuan Yu Comparison of public peak detection algorithms for MALDI mass spectrometry data analysis BMC Bioinformatics. 2009; 10: 4. Published online 2009 January 6. doi: 10.1186/1471-2105-10-4 http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2631518/\nInstead, I got some hints on a rather simpler approach from Daniel Mayer by asking a question on the SuperCollider mailing list.\nHere\u0026rsquo;s the code I eventually came up with:\n( ~name = \u0026quot;glycine\u0026quot;; ~path = Document.current.dir.asString++\u0026quot;/\u0026quot;++ ~name ++\u0026quot;.csv\u0026quot;; f = CSVFileReader.readInterpret(~path);\nf = ((f.flop[1] * -1) + 1).normalize; // these three lines remove plateaus in the data, // otherwise we get missing 'peaks' in the analysis // some int/float voodoo needed here! f = (f*100).asInteger; f = f.differentiate.removeEvery([0]).integrate; f = f/100; // the magic line which finds the peaks ~peaksIndices = f.differentiate.sign.findAll([1,-1]); // putting the data back together again g = Array.fill(f.size, 0); ~peaksIndices.do { |i| g[i] = f[i] }; ~amps = g; [f,~amps].plot(~name, Rect(840,0,600,450)); ~freqs = (36..128).resamp1(f.size).midicps; ```{ Splay.ar(Klank.ar([~freqs, ~amps, nil], PinkNoise.ar(0.01))) }.play; )``\nAt the very end of the plot you can see one of the problems: this method finds any and all local peaks, including ones which to the eye look unimportant:\nI think what would be needed here would be some low-pass filtering to get rid of small glitches. However, the musical results so far are quite good: once again, here\u0026rsquo;s a short gesture made by crossfading from one compound to another:\n[soundcloud url=\u0026ldquo;http://api.soundcloud.com/tracks/52949967\" iframe=\u0026ldquo;true\u0026rdquo; /]\n"},{"id":56,"href":"/posts/2012-07-18-sonifying-ir-spectroscopy-data-automating-pitch/","title":"Sonifying IR spectroscopy data - automating pitch","section":"Blog","content":"Going off in a bit of a different direction here, using the data as automation to drive the pitch of a synth:\n( f = CSVFileReader.readInterpret(Document.current.dir.asString++\u0026quot;/water.csv\u0026quot;);\nf = ((f.flop[1] * -1) + 1).normalize(48,84); //midinotes\nPmono( \\default, \\midinote, Pseq(f, inf), \\dur, 0.005).play )\nIn this recording, looping up the three chemicals one by one. Kind of cute - early days for this approach.\n[audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2008/09/pmono01.mp3\"][/audio]\npmono01.mp3\n"},{"id":57,"href":"/posts/2012-07-17-sonifying-ir-spectroscopy-data-chords/","title":"Sonifying IR spectroscopy data - 'chords'","section":"Blog","content":"Finding the .resamp1 method in SuperCollider gave me an idea for reducing this rather large set of data into something perhaps more musically useful. Could I make something more like a tonal chord, with pitches repeated in every octave?\nI first drastically resampled my data into just twelve points:\nf = ((f.flop[1] * -1) + 1).resamp1(12); These would then be the probabilities of those twelve pitch classes appearing across a range of eight and a half octaves:\nf = (f++f++f++f++f++f++f++f++f[..7]); // 104 notes\nThen what I did was to multiply this chordal structure by the original data, so that my final sound is the \u0026lsquo;glycine chord\u0026rsquo; amplitude modulated (sort of) by the absorbtion data.\nHere\u0026rsquo;s the final code:\n( ~name = \u0026quot;glycine\u0026quot;; ~path = Document.current.dir.asString++\u0026quot;/\u0026quot;++ ~name ++\u0026quot;.csv\u0026quot;; f = CSVFileReader.readInterpret(~path); g = f;\nf = ((f.flop[1] * -1) + 1).resamp1(12); f = (f++f++f++f++f++f++f++f++f[..7]); // 104 notes g = ((g.flop[1] * -1) + 1).resamp1(104); // 104 samples of orig graph ~amps = f.cubed * g; // combining two approaches ~amps = ~amps.normalize; ~amps.plot(~name, Rect(840,0,600,450)); ~freqs = (25..128).midicps; ```{ Splay.ar(Klank.ar([~freqs, ~amps, nil], PinkNoise.ar(0.01))) }.play; )``\nI used this approach to make the sound below, which crossfades from glycine to tyrosine to water, then back to glycine again.\n[soundcloud url=\u0026ldquo;http://api.soundcloud.com/tracks/52370172\" iframe=\u0026ldquo;true\u0026rdquo; /]\n"},{"id":58,"href":"/posts/2012-07-16-sonifying-ir-spectroscopy-data/","title":"Sonifying IR spectroscopy data","section":"Blog","content":"I\u0026rsquo;m in the very early stages of a collaborative project with Dr Steven Ford, Senior Research Fellow and QC Manager at the Cancer Research UK Formulation Unit of Strathclyde University. Steve came to me with an idea about sonifying IR spectroscopy data, with a view to perhaps drawing some creative parallels between vibrations at the atomic scale and musical sound.\nSteve sent me some IR data relating to three compounds, water, glycine and tyrosine, and I\u0026rsquo;ve been trying some things out in SuperCollider. Here\u0026rsquo;s a plot of the data which Steve sent me: Thinking in terms of sound, my immediate thought was to try to scale those resonances into the audio region. Here\u0026rsquo;s one of my first attempts:\n( ~name = \u0026quot;water\u0026quot;; ~path = Document.current.dir.asString++\u0026quot;/\u0026quot;++ ~name ++\u0026quot;.csv\u0026quot;; f = CSVFileReader.readInterpret(~path);\n~amps = f.flop[1]; // array of amplitudes ~amps.plot(~name, Rect(840,0,600,450));\n~freqs = Array.series(f.size, 40, 100); // size, start, step\n{ Klank.ar(`[~freqs, ~amps, nil], PinkNoise.ar(0.01)) }.play; )\n[audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2008/09/water01.mp3\"][/audio]\nwater01.mp3\nThere are 784 points of data here, and I\u0026rsquo;ve just mapped those arbitrarily to a bank of 784 resonators, spaced 100 Hz apart, starting at 40Hz. It sounds pretty nasty. Then it occured to me that Steve\u0026rsquo;s data is for transmittance, not absorbance: the points of interest are the troughs, not the peaks, the graph is upside down for what I wanted to do. So:\n( ~name = \u0026quot;tyrosine\u0026quot;; ~path = Document.current.dir.asString++\u0026quot;/\u0026quot;++ ~name ++\u0026quot;.csv\u0026quot;; f = CSVFileReader.readInterpret(~path);\n~amps = ((f.flop[1] * -1) + 1).cubed; // invert, massage ~amps.plot(~name, Rect(840,0,600,450));\n~freqs = (64..128).resamp1(f.size).midicps;\n{ Klank.ar(`[~freqs, ~amps, nil], PinkNoise.ar(0.01)) }.play; )\nHere I was also starting to think about how to bring out the peaks in the data, hence the .cubed. This does make the data \u0026lsquo;pointier\u0026rsquo;, but at the expense of the smaller peaks. A slightly different strategy with the frequencies here also, 784 microtonal pitches between midi notes 64 and 128. It still sounds really pretty nasty:\n[audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2008/09/tyrosine01.mp3\"][/audio]\ntyrosine01.mp3 "},{"id":59,"href":"/posts/2012-05-01-gathering-of-the-gamelans-day-2-afternoon/","title":"Gathering of the Gamelans - Day 2, afternoon","section":"Blog","content":"After lunch today we had a joint session, with three people presenting their experience of teaching gamelan in schools and universities. I am presently engaged on a project to attempt to establish a gamelan at Stevenson College Edinburgh (soon to be Edinburgh College), so this area is of particular interest to me.\nRuth Andrews runs a gamelan programme for 12-17 year olds at the International School of Amsterdam, which sounds like it would be a model to aim for. The gamelan is permanently installed in a large room, and all the students have gamelan activity in every year of their studies. Links are made between the cultural and historical perspectives offered by the gamelan and other areas of the curriculum. The gamelan seems to have become a central, shared experience for everyone at the school: a musical ensemble where everyone takes part on an equal level, with no soloists or stars.\nAndy Gleadhill is a music officer in Bristol, where gamelan is firmly established as a whole-class music activity within the primary curriculum. There are 66 (!) specially designed sets of gamelan instruments in their schools. Andy presented some material from a particular project which combined Digital Audio Workstation technology – loops and recording in GarageBand – with gamelan, the students working to put together a hybrid version of a Black Eyed Peas song.\nMaria Mendonça outlined a degung programme which she runs at Kenyon College in the States. I don\u0026rsquo;t fully understand the American system, but this seems to be one-semester class which can be taken by either music students or students on other degrees. She works largely by ear rather than using notation, and spoke very positively about the level playing field which can be established between trained and untrained musicians. She described a teaching model where the students have a two-hour class, followed by an hour to work as a group on their own. She seems to use peer teaching extensively, on the very simple model of having students swap around and teach each other the parts: a practice I have also employed.\nThis was an informative and inspirational setting. Particularly impressive was the roster of visiting artists which Maria had managed to get, which included, wait for it, Euis Komariah, Nano S and Balawan! (Ok, perhaps these names may not mean much to non-gamelan specialists… I was about as impressed as I would have been if she said she had got Ella Fitzgerald, Duke Ellington, and Charlie Christian :)\nLater in the afternoon, Charlotte Pugh and John Jacobs gathered a large group of us together for a session billed as a gamelan \u0026lsquo;improvisation\u0026rsquo; workshop, although it seems to me it was more like a session on group devising. Charlotte played to us the outline of a medium length phrase in slendro, which we kind of copied back as a group, or in small teams, in an approximate fashion. John then gave us a similar phrase on the pelog instruments which we also worked on in small teams, and then both pieces of material were combined. A very chaotic sound resulted, but with some definite sense of shape. A short discussion ensued as to what we might then do if this was the first week of an eight-week project. Would the work crystalise into a composition, or would one seek to open up the process to a much more free and unpredictable form of improvisation?\nAn interesting point of practice which I will file away for future use: they had a couple of mics up, and a dedicated engineer who was able to play back to us instantly the short chunk we had just put together. This instant feedback was a great way for the group to be aware of the whole picture, not just what each subgroup was doing.\n"},{"id":60,"href":"/posts/2012-05-01-gathering-of-the-gamelans-saturday-rehearsals/","title":"Gathering of the Gamelans, Saturday rehearsals","section":"Blog","content":"Substantial chunks of the day were taken up by a series of rehearsals for the wayang. The venue was a modern dining hall, with a kind of semicircular shape. Spacially this allowed for a very good arrangement, with room for audience all around, and a separate staging area off to one side for dance and video. The ceiling was perhaps a little low, and the sound less resonant than might have been ideal.\nThere were seven amalgamated gamelan groups from over the UK who needed to rehearse: around 170 musicians in total! Coordinating all of this was musical director John Pawson, and by and large we got to do what we needed to do, albeit not without a certain amount of last minute stress. A day of hurry up and wait, mostly, with the Scottish group almost missing out on our final fifteen minute run-through.\nNow, an interesting aside, but I want to tread carefully, as this concerns an overheard remark. One of the groups was about to rehearse a piece which incorporated clarinet, and someone from one of the other groups was apparently heard to say \u0026lsquo;Here comes the sacrilege\u0026rsquo;. Maybe this was a joke: probably it was a joke. I entirely respect the conservative impulse in traditional musics, but \u0026lsquo;sacrilege\u0026rsquo; seems a very strong word. Of course we were all thinking, \u0026lsquo;Wait till he hears the bagpipes!\u0026rsquo;.\nAn excellent Indonesian meal was provided for the participants: I had the rendang, always a favourite!\n"},{"id":61,"href":"/posts/2012-05-01-gathering-of-the-gamelans-saturday-sessions/","title":"Gathering of the Gamelans, Saturday sessions","section":"Blog","content":"Today\u0026rsquo;s conference activities were somewhat disrupted by a revised schedule of wayang rehersals, which also caused our Scottish group a certain amount of last minute phone calls to try to get everyone there in time. I was fortunately able to make Helen Loth\u0026rsquo;s paper session \u0026lsquo;\u0026ldquo;Why gamelan, couldn\u0026rsquo;t we just use steel-pans?\u0026rdquo;: The use of gamelan with special needs groups and populations\u0026rsquo;. Helen is engaged on doctoral research in this area, and presented an illuminating account of her findings so far. Her application of the term \u0026lsquo;special needs groups\u0026rsquo; is very broad: in effect she is surveying pretty much the a full range of what I would might have called \u0026lsquo;community music\u0026rsquo; with gamelan in the UK. After a literature review, she presented a series of tables full of interesting nuggets of information: for instance, the most common timescale for this kind of work seems to be the (often criticised) one-off workshop, followed by the 1-2 week residency. I was particularly interested in a diagram which laid out people\u0026rsquo;s perceived feelings about the different tunings one could potentialy use, slendro, pelog, Sundanese and two Balinese tunings. I was also fascinated by some of the negative perceptions of gamelan music which she had identified in her study. With the rescheduled day there was little time for discussion: this would have been an interesting area to probe further.\nI\u0026rsquo;ve now been to two really excellent workshops by Jonathan Roberts. A number of years ago I participated in an illuminating session on wayang puppets and puppetry, and this morning he gave us a great section on gerongan, the unison (mostly male) singing which accompanies Javanese gamelan. In a brave but completely correct move, I think, Jonathan had us do hardly any singing, but spent the majority of the time on Javanese pronunciation. There are a number of sounds in the language which are not found in English, which we worked through in some detail: at times the session almost turned into – bilabial fricative?! – a lecture on phonetics. I still struggle to hear the difference between those d and t sounds, but I think I have clearer idea how to make them.\nAfter the pronunciation, Jonathan took us through some techniques in Javanese vocal production. He started off by busting the myth that it is \u0026rsquo;nasal\u0026rsquo;. Instead, we were to try yawning, to start to feel the action of the pharynx and how that could be brought into action to produce a kind of vocal resonance which he called \u0026rsquo;twang\u0026rsquo;. I can\u0026rsquo;t do it yet, but at least I\u0026rsquo;m going to stop singing through my nose!\n"},{"id":62,"href":"/posts/2012-05-01-gathering-of-the-gamelans-saturday-wayang-lokananta/","title":"Gathering of the Gamelans, Saturday, Wayang Lokananta","section":"Blog","content":"At last, we get to the piece we have all been working towards for so many months:\nKanda Buwana is the company name of dhalang Matthew Isaac Cohen. I have known Matthew for a number of years, most notably during the period when he was at Glasgow University. Matthew was responsible for bringing dhalang Ki Joko Susilo to Scotland, and Mas Joko, as we called him, was in turn reponsible for a transformation in the approach of Gamelan Naga Mas. He brought to us a great chunk of highly distinctive repertoire, most of it derived from the wayang, which we still play today: a talu, unusual srepeg and sampak, and Joko\u0026rsquo;s arrangements of such pieces as Caping Gunung, Gambang Suling and Wong Donya. Our musical director Signy Jakobsdottir soaked up a year\u0026rsquo;s worth of wayang drumming from Joko: Matthew was always around, playing peking devising wayang in English with Joko, with his then young daughter Hannah climbing all over him in rehearsal. Happy days.\nTo commemorate 30th anniversary of York\u0026rsquo;s Gamelan Sekar Petak, Matthew created \u0026lsquo;Lokananta, or the Playerless Gamelan\u0026rsquo;, interweaving a number of different oral and literary sources with music which John Pawson had garnered from gamelan groups across the UK. Each section of the wayang was accompanied by a different group: in order, Cardiff Gamelan, Gamelan Midwest (comprising Cheltenham and Oxford), Gamelan Scotland (Aberdeen University, Gado-gado and Naga Mas), Gamelan Sekar Petak (York), Gamelan South East (Cambridge, Siswa Sukra, Southbank Gamelan Players), Gamelan South West (Bath Spa, Bristol), and Gamelan North (Chopwell, Dwi Gambira Sari, Durham.)\nA full DVD of the show is in preparation, and I\u0026rsquo;m not going to attempt to describe the whole thing. The high point of the show for me was John Pawson\u0026rsquo;s arrangement of Subakastawa Nyamat. Arrangement is too small a word for it: this was a unique artistic creation, bringing together all of the tunings, players and gamelans in a melding of Kodok Ngorek and Subakastawa. A great wave of building emotion as the first gamelan descended from the heavens, and all the musicians spread around the room gradually joined in singing \u0026lsquo;Mideringrat…\u0026rsquo;:\nA moment I will never forget.\nThough I say so myself, Gamelan Scotland acquitted themselves extremely well: \u0026lsquo;blown away\u0026rsquo; was the response we seemed to get from everyone, not least for the dramatic entrance of our piper Hazen Metro on Margaret Smith\u0026rsquo;s piece Iron Pipes. Another emotional moment for me as Mags sang her arrangement of Ca\u0026rsquo; the Yowes, and a scary moment for me when I had to lead the entire audience in a brief kecak! I also played Gamelunk, of course, which came off pretty well.\nAs to the wayang itself: the amplifiation of Matthew\u0026rsquo;s voice was not entirely satisfactory on the musician\u0026rsquo;s side of the screen, and there was much I could not follow. Matthew has a wicked sense of humour, and can be very good at the interplay and in-jokes between the musicians and the puppeteer: again, some of this seemed to get lost. I was impressed with Matthew\u0026rsquo;s puppet technique, including a great trick of catching the limbs of one puppet between another and the screen, used to great effect in some of the fight scenes.\n"},{"id":63,"href":"/posts/2012-04-30-gathering-of-the-gamelans-day-1/","title":"Gathering of the Gamelans - Day 1","section":"Blog","content":"Day 1 of the Gathering of the Gamelans here at York was very exciting and engaging. A great chance to catch up with old friends from the gamelan world, put faces to names, and meet new people.\nI left Glasgow purposely very early in order to get down in time to catch Charles Matthews\u0026rsquo; presentation \u0026lsquo;Searching for an approach to gamelan and electronic music\u0026rsquo;. I\u0026rsquo;ve been following Charles on twitter on his recent trip to Indonesia where he was exploring some of these approaches in their native setting, and I was very curious to see what he has been up to. The session started with a performance devised in collaboration with Charlotte Pugh, for gender and laptop. On screen we were able to watch Charles\u0026rsquo; Max patch in action, as he created what one might term \u0026rsquo;electroacoustic cengkok\u0026rsquo; to compliment Charlotte\u0026rsquo;s gender on \u0026lsquo;Sri Katon\u0026rsquo;. One of the most interesting aspects was his use of a fader on a control surface to manipulate time, \u0026lsquo;scratching\u0026rsquo; his way through each gotra: a unique approach, as far as I am aware.\nMore pieces followed, showing a variety of improvisatory approaches, some manipulating Charlotte\u0026rsquo;s live sound. Overall the music was mostly slow and evolving: I would be interested to see whether these approaches would work in a more lively style.\nWe then had an excellent presentation by Sarah Kekus, Ali McCaw, and Chris Stones, \u0026lsquo;Exploring sound worlds – creative exploration of traditional cultures from Northern England and Central Java\u0026rsquo;. A great three-way act, with Chris starting off by getting a few people down from the audience, myself included, to work up a texture for lithophone and gamelan. One this was established, Ali gave us a performance with some wayang golek, including an appearance from a puppet of Peter Crosthwaite, a C19th figure who both travelled in the Far East and established a tradition of Cumbrian lithophony. Sarah Kekus outlined her experiences of gamelan in Cumbria, beginning with an iron Suhirdjan gamelan which she obtained for her school. An excellent presentation of a (perhaps distinctively British?) strand of community/education work with gamelan.\nNeil Sorrell lead a session entitled \u0026lsquo;Composing for Western instruments and gamelan\u0026rsquo; by referring to something he calls the \u0026rsquo;three Ts\u0026rsquo;: timidity, timbre and tuning. By \u0026rsquo;timidity\u0026rsquo; he seemed to mean a dimension of fear versus daring, when writing for gamelan, which he instanced by playing the opening snatch of Harjito\u0026rsquo;s bagpipe piece \u0026lsquo;Sekaten\u0026rsquo;. His point being, I think, that Indonesian composers are not timid when it comes to innovation!\nGuest musician Pak A.L. Suwardi then gave an inspiring talk about his approach to composition, showed some slides of the Gamelan Gentha, a set of self-constructed experimental instruments, and played an extract of another recent project including his own instruments, called I think \u0026lsquo;Planet Harmonic\u0026rsquo;. Many of his comments resonated very strongly with me, particularly in reference to composing for a particular context.\nAris Daryono\u0026rsquo;s presentation of his work was slightly hampered by a laptop disaster which meant he could not bring recordings for us to hear. However, he did present a page from a fully notated score for a piece for flute and gender. He talked about his efforts to have the music which he writes for Western instruments and gamelan presented in straight concert settings, rather than being automatically programmed into some sort of ethnomusicological ghetto. Having recently managed to get a laptop piece performed as part of a regular concert programme, and not automatically placed into the \u0026rsquo;electroacoustic\u0026rsquo; concert, I have a sort of sideways sympathy for the point he makes.\nClive Wilkinson then talked a little about some of his experiences composing for gamelan, including playing us a snatch of his \u0026lsquo;Spindrift\u0026rsquo; from Manchester. I wrote about this piece at the time, and have in fact been invited by Clive to take part in a performance on Sunday, which will be an interesting experience.\nA great first day: a refreshingly non-academic atmosphere overall. No-one has so far presented a \u0026lsquo;paper\u0026rsquo; at all, which I miss only a very little bit.\n"},{"id":64,"href":"/posts/2012-04-30-gathering-of-the-gamelans-day-2-morning/","title":"Gathering of the Gamelans - Day 2, morning","section":"Blog","content":"Our first session today was the fascinating tale of the Dutch group \u0026lsquo;Babar Layar\u0026rsquo;, as researched by Maria Mendonça. It\u0026rsquo;s a story worthy of Hollywood: a group of Dutch teenagers who decided to construct their own gamelan under the Nazi occupation, going on to become a key influence on gamelan in Europe and the States. There\u0026rsquo;s a clip of them playing at an Eistedfodd in Wales in 1953 (about 1'50 into that clip).\nAfter Maria\u0026rsquo;s session I took a break, and missed what seems to have been one of the best workshops of the conference \u0026lsquo;The Song of the Gong: teaching Javanese gamelan to the early-years with reference to Kodály, Dalcroze \u0026amp; Alexander\u0026rsquo; by Nikhil Dally. I gather this was a very grounded, embodied, vocal approach to teaching basic gamelan cycles.\nOver lunch we had \u0026lsquo;a concert of contemporary music for chamber gamelan ensembles, with electronics flute, banjo and vibraphone\u0026rsquo;. The standout piece was undoubtably Robert Campion\u0026rsquo;s \u0026lsquo;Gendèr Study 3\u0026rsquo;. The idea of making a \u0026lsquo;study\u0026rsquo; for this complex and hard to master instrument makes perfect sense: a tightly structured, sparky piece, performed with great focus and intensity by the composer himself.\nJon Hughes, John Jacobs and Charlotte Pugh had collaborated on a piece which seemed to comprise a layer of devised loops and fragments, recorded and diffused over an ambisonic rig, combined with live ?improvised rebab from Charlotte and planned ostinato material from John on gender paneruus and Sundanse drums. This worked well for me, particularly the rhythmic energy of the piece.\nAris Daryono\u0026rsquo;s piece for two sarons wrung a large number of different ideas from the basic idea of imbal: perhaps too many ideas? Ellen Jordan had devised a collision between the traditional American tune Wayfaring Stranger and Wilujeng, with voice, rebab and banjo. A good idea, with perhaps an over-fiddly execution.\nDaniel March\u0026rsquo;s \u0026lsquo;Pieces of Five and Three\u0026rsquo; and Symon Clarke\u0026rsquo;s \u0026lsquo;Three Exits\u0026rsquo; were attractive and carefully written, but perhaps a little abstract for my taste.\n"},{"id":65,"href":"/posts/2012-04-23-gathering-of-the-gamelans/","title":"Gathering of the Gamelans","section":"Blog","content":"From Thursday of this week to Monday of next I\u0026rsquo;m going to be at the Gathering of the Gamelans in York. This event is part academic conference, and partly a performative celebration of gamelan in the UK, most particularly the 30 years that Gamelan Sekar Petak has been at the University of York.\nFor the last couple of months, gamelan groups all over the UK have been rehearsing both separately and collaboratively towards \u0026lsquo;Lokananta, Gamelan of the Gods\u0026rsquo;. This will be a wayang kulit, an all-night shadow puppet play in the Central Javanese style, under the direction of dhalang Matthew Isaac Cohen. To translate dhalang as \u0026lsquo;puppeteer\u0026rsquo; is about as misleading as translating wayang as \u0026lsquo;shadow puppet play\u0026rsquo;: both descriptions are accurate, but neither captures the breadth and depth of the form. Over the course of approximately seven hours, the dhalang has the responsibility for creating, leading and performing a multi-modal piece using puppetry, song, dance, and the voice, encompassing everything from high philosophy to low humour, from archaic texts in high Javanese to the most contemporary of references.\nThis concert in York represents a very rare opportunity to see a complete wayang performed in English. I attended a number of performances in Java, which were fascinating but impossible to follow in detail without a knowledge of the language. (One exception to this was a performance by Ki Purbo Asmoro\u0026rsquo;s with live translation into English by Kitsie Emerson: a two-hour video of one of these is available here, with at least some of the translation visible).\nThe musical direction for this project has been undertaken by one of the UK\u0026rsquo;s most pre-eminent gamelan musicians, John Pawson, himself a York graduate. Both Matthew and John are keen to keep some surprises up their sleeves, so I\u0026rsquo;d better not reveal too much! Suffice to say that the Scottish Gamelan (made up of members of Naga Mas and Gado-Gado from Glasgow, and a group from Aberdeen University) will have something very culturally distinctive to offer during our segment of the show. And it ain\u0026rsquo;t shortbread. (Or whiskey. Or tartan. Or golf.)\n"},{"id":66,"href":"/posts/2012-04-20-performances-at-plug/","title":"Performances at Plug","section":"Blog","content":"I\u0026rsquo;m having two new pieces performed at the Plug festival at the Royal Conservatoire of Scotland next week. The first is called Dr Mueller? Dr Mueller!? Oh, boy :( and is a postlude to Spiricom, the third piece in Gordon McPherson’s 2007 trilogy Ghosts. The ‘spiricom’ was a psuedoscientific electronic device built by a couple of cranks in the 1980s, who convinced themselves that with it they could hear and talk to dead people including, supposedly, a certain ‘Dr Mueller’.\nThe piece is for clarinet and acoustic laptop: by which I mean a laptop with no additional amplification, transforming the sounds of the clarinet, to be played by Fraser Langton. This one is in Plug 1, the Monday lunchtime concert.\nThe second piece is on Wednesday evening: The Black Rain again involves laptop and live instruments, this time five players from the Scottish Ensemble through a SuperCollider patch, more on that one below.\n"},{"id":67,"href":"/posts/2012-03-19-working-on-the-black-rain/","title":"Working on 'The Black Rain'","section":"Blog","content":"After the success of the \u0026lsquo;The Seventh Voyage\u0026rsquo;, I have high hopes for my next two laptop-and-acoustic-instruments pieces, both to be performed at Plug 12 in a month\u0026rsquo;s time. Today I\u0026rsquo;m working on \u0026lsquo;The Black Rain\u0026rsquo;, which is for five players from the Scottish Ensemble - two violins, viola, cello and double bass - and live processing in SuperCollider. Here\u0026rsquo;s the (rather long and convoluted) programme note:\n‘When the last trace of the rocket’s presence, a whitish haze, had been absorbed by the atmosphere, when the wandering sandy waves gradually began to cover up the naked rock of the ground, at the same time filling in the deserted digging spaces – only then, much later, did a dark cloud gather in the west. Hovering low above the ground it pushed closer, grew, encircled the landing area with a threatening arm. There it remained, motionless.\nAs the sun was about to set, a black rain fell on the desert.’\n‘The Black Rain’ takes its title from the first chapter of Stanis!aw Lem’s 1967 science fiction novel ‘The Invincible’, in which a mighty spaceship and her crew are overcome by a race of microscopic mechanical flies, individually insignificant, but capable of joining together into a vast quasi-intelligent ‘cloud’: surely one of the first fictional works to speculate on the possibilities of nanotechnology, calling to mind such devices as the nanostats which inhabit Neal Stephenson’s 1995 novel ‘The Diamond Age’, and the EDust, or Everything Dust, in Iain M. Banks 2000 ‘Look to Windward’.\nAesthetically, ‘The Black Rain’ carries forward the composer’s ongoing reconstruction of the career of his fictional alter ego Edward ‘Teddy’ Edwards. Something like:\n‘In 1959, Edwards created a work for string quartet (or quintet?) and five (or four?) taperecorders, incorporating radio equipment borrowed from Aldermaston, where he was at the time employed as an engineer on the ill-fated Blue Streak missile system. Working from his original sketches, I have replicated the piece using the music programming language SuperCollider, with the addition of a reconstructed lost (?) part for double bass.’\nIn terms of musical devices, ‘The Black Rain’ represents, through self-quotation, a critique of a group earlier works of mine (‘smir’, ‘4thought’, ‘5lipside’ etc), all of which float angular melodies across polymetric rhythmic frameworks, usually according to some quartal scheme, and usually, it would seem, in roughly the same key.\n"},{"id":68,"href":"/posts/2012-03-08-premiere-of-the-seventh-voyage/","title":"Premiere of 'The Seventh Voyage'","section":"Blog","content":"I\u0026rsquo;m happy to say that my collaboration with pianist Silviya Mihaylova The Seventh Voyage, for two pianos and laptop, has been given pride of place as the closing work in the Royal Conservatoire of Scotland\u0026rsquo;s piano festival.\nThe concert is at 1300 this Monday 12 March, in the Guinness Room. Tickets are available from the RCS box office, although, confusingly, they still have the wrong concert listed on the website https://boxoffice.rcs.ac.uk/, it\u0026rsquo;s billed as \u0026lsquo;Piano and Strings\u0026rsquo;. Tickets are £7/5.\nUpdate also on the programme, all piano musice: Haydn Sonata in E Major, Liszt Spanish Rhapsody, Enescu Pavana and Silvestri Baccanale.\n"},{"id":69,"href":"/posts/2012-02-10-work-in-progress-the-seventh-voyage/","title":"Work in progress: 'The Seventh Voyage'","section":"Blog","content":"I\u0026rsquo;m working on about three new pieces at the moment. The second of these is a collaboration with pianist Silviya Mihaylova on a shortish work for piano and laptop. The piano part is kind of done: Silviya took my sketches and added some ideas of her own. Apart from that, I have a program note, and some programming:\nThe title of this piece is taken from Stanisław Lem’s 1971 science fiction comedy classic ‘The Star Diaries’. In ‘The Seventh Voyage’ the hero of the stories, hapless cosmonaut Ijon Tichy, finds his rocket trapped in a loop of time. His attempts to repair the ship’s rudder are continually frustrated by the appearance of younger and older copies of himself:\n“Just a minute,” I replied, remaining on the floor. “Today is Tuesday. Now if you are the Wednesday me, and if by that time on Wednesday the rudder still hasn’t been fixed, then it follows that something will prevent us from fixing it, since otherwise you, on Wednesday, would not now, on Tuesday, be asking me to help you fix it. Wouldn’t it be best, then, for us not to risk going outside?”\n“Nonsense!” he exclaimed. “Look, I’m the Wednesday me and you’re the Tuesday me, and as for the rocket, well, my guess is that its existence is patched, which means that in places it’s Tuesday, in places Wednesday, and here and there perhaps there’s even a bit of Thursday. Time has simply become shuffled up in passing through these vortices, but why should that concern us, when together we are two and therefore have a chance to fix the rudder?!”\nfrom Stanisław Lem ‘The Star Diaries’ – Chapter 1 ‘The Seventh Voyage’\nLots under the hood, but here\u0026rsquo;s the front page of the pd patch so far:\n"},{"id":70,"href":"/posts/2012-02-06-composers-screenshots/","title":"Composer's screenshots","section":"Blog","content":"\n"},{"id":71,"href":"/posts/2012-01-30-working-on-a-new-piece/","title":"Working on a new piece","section":"Blog","content":"Here\u0026rsquo;s how composing looks to me at the moment:\n( a=[46!5,39!4,41!4,36!3,44!3,43!2,37!2,38,42].flat; Pbind(\\midinote, Pstutter( Pwhite(5,17,inf), //min max number repeated notes Pxrand(a,10) //get 10 pitches (actually 8???) ), \\dur, 0.25, \\legato, 0.5 ).play; )\n"},{"id":72,"href":"/posts/2012-01-26-some-notes-from-a-concert/","title":"Some notes from a concert","section":"Blog","content":"Took the time to go to a concert of contemporary music tonight, a rare pleasure for me these days. Psappha, at the Royal Conservatoire of Scotland, playing a concert of largely new work. Sean Friar\u0026rsquo;s Scale 9 which opened the programme was likeable and energetic, a sort of andante and allegro, or rather andante and blues, in a post- (very-post-) Gershwin vein. Nice to see an ensemble conducting themselves.\nI like my flavours strong and simple, and Francesca Le Lohé\u0026rsquo;s Blind Men and an Elephant was a little too detailed and finely wrought for my taste. It had the merit of turing out to be shorter than I thought it would be, which sounds snarky, but is actually an honest and well-intentioned comment: a compressed, rich piece.\nShows how out of touch I\u0026rsquo;ve become that I didn\u0026rsquo;t even know Gordon McPherson had a big three movement prem tonight, Stunt Doubles. The gag here was having a synthesised ensemble play along with the real players. This worked very well: even just a few years ago this would have been a very different piece, but today\u0026rsquo;s huge sample libraries make a much better job of it than the old 128 midi sounds. The first movement was… maximal, a million notes, but still very clear and structured. In the second movement Gordon dipped into a jazz bag which he normally keeps very well hidden, up in the loft somewhere behind an old sofa: we all liked this.\nThe third movement gave me some pause, with a slightly, er, naff, pastiche, of a filmic whistly-march type tune. The end of this piece oddly made more sense to me, where we heard this tune again, this time on the synthesised ensemble. Overall I thought this was a good piece, a bit tiring in places.\nDimitrios Skyllas New Miniatures for the Universe rather exceeded my C21st 140-character attention span. Seemed to be rather large miniatures. And, the Steve Reich Double Sextet: boring.\nBut, very well played by Psappha, as were all the pieces in this well balanced and engaging concert.\n"},{"id":73,"href":"/posts/2011-12-27-nine-hours-of-improvisation/","title":"Nine hours of improvisation","section":"Blog","content":"My friend and colleage Kath has persuaded me to sign up for a ten-hour sponsored improvisation which she is organising. The event is in support of Common Wheel, a Glasgow-based charity who provided \u0026lsquo;meaningful activity for people with mental illness\u0026rsquo;. They have two strands to their work, a bicyle project and the music project \u0026lsquo;Polyphony\u0026rsquo;. The latter runs at Gartnaval Hospital, where they are asking interested musicians to join them on 28 January for ten hours of sponsored musical improvisation.\nI\u0026rsquo;ve agreed to sign up for nine hours, which is the longest they are allowing people to attempt. I\u0026rsquo;m intending to play a variety of instruments, probably all piped through the laptop, maybe sruti box, trumpet, ketipung, and a synth. Should be interesting! As an experiment I had a wee go myself at improvising vocally and over the sruti box the other night, was able to keep going for well over an hour. Still, nine hours… I wonder how that is going to feel!\nAs well as the musical challenge, of course, it\u0026rsquo;s about the money. If you\u0026rsquo;d like to sponsor me, you can use the donate link on the Common Wheel website, send me an email as well so that I know, tedthetrumpet (at) gmail.com.\n"},{"id":74,"href":"/posts/2011-12-11-recording-from-night-of-the-earthmen/","title":"Recording from 'Night of the Earthmen'","section":"Blog","content":"[soundcloud url=\u0026ldquo;http://api.soundcloud.com/tracks/30240394\"]\nNot be much to listen to, maybe, but feels an important moment for me: a new direction after finishing the PhD, satisfyingly far away from score-based contemporary \u0026lsquo;classical\u0026rsquo; nonpop, or whatever you call all that stuff. Next up: more of this kind of thing, plus more gamelan. Happy days.\n"},{"id":75,"href":"/posts/2011-12-08-night-of-the-earth-men/","title":"Night of the Earth Men","section":"Blog","content":"I\u0026rsquo;m doing, um, I guess my first ever solo electro-junk improv gig on Friday 5 December. Ulp. Here\u0026rsquo;s the poster… I\u0026rsquo;m almost embarrased to say:\nLet\u0026rsquo;s see, the plan includes… a Pd patch running on the netbook, probably SuperCollider running on the (new secondhand) MacBook Pro. The Novation BassStation and the Hammond AutoVari 64, a mixing desk, and a pocket trumpet with a piezo mic inside a harmon mute. That\u0026rsquo;s what I\u0026rsquo;ve been experimenting with so far, anyway\u0026hellip;\n"},{"id":76,"href":"/posts/2011-11-28-working-on-a-postlude-to-spiricom/","title":"Working on a postlude to 'Spiricom'","section":"Blog","content":"I\u0026rsquo;ve been working on a piece for this year\u0026rsquo;s Plug festival at the Royal Conservatoire of Scotland, which will be in May sometime. The theme this time round is \u0026lsquo;postludes\u0026rsquo;. Head of Composition Gordon McPherson has invited all the composers here, including staff like myself, to compose something which draws on, or reflects, or comments upon in some way, a piece from a previous Plug festival.\nI\u0026rsquo;ve found myself drawn immediately to one of Gordon\u0026rsquo;s own pieces from 2007, \u0026lsquo;Spiricom\u0026rsquo;, part of a trilogy of pieces called \u0026lsquo;Ghosts\u0026rsquo; which deal in various ways with death and a possible afterlife. \u0026lsquo;Spiricom\u0026rsquo; refers to\u0026hellip; we\u0026rsquo;ll, you can google it, a strange and mad episode in the history of pseudoscience, a couple of cranks who convinced themselves they had built a machine which would talk to dead people.\nMy postlude will be for solo clarinet and acoustic laptop: by which I mean a laptop operating entirely by itself, using just the internal mics and speakers. I\u0026rsquo;ve written a patch in Pd which will (quietly) transform long notes played by the clarinet, these long notes being a (very) approximate by-ear transcription of certain passages within Gordon\u0026rsquo;s original piece. I have Fraser Langton lined up to play the clarinet, and we\u0026rsquo;ve had a wee try out with the patch: sounds ok.\nA frustrating, ugly, boring piece to listen to, I imagine. But it will only be short :)\n"},{"id":77,"href":"/posts/2011-11-02-straight-no-chanter/","title":"Straight No Chanter","section":"Blog","content":"\n"},{"id":78,"href":"/posts/2011-09-19-running-in-the-dark-in-bremen/","title":"'Running in the Dark' in Bremen","section":"Blog","content":"Just found out that the Bremen gamelan group Gamelan Kancil are playing Running in the Dark on Nov 27, working from the score they found here. Hope they make a recording, be curious to see what they make of it…\n"},{"id":79,"href":"/posts/2011-08-29-cheetah-mq8-first-go/","title":"Cheetah MQ8, first go","section":"Blog","content":"I\u0026rsquo;ve just got a new toy (tx John!). It\u0026rsquo;s a Cheetah MQ8 midi sequencer. This is UK made, apparently released sometime in the late 80s as a competitor to the Alesis MMT-8. I\u0026rsquo;ve only just started to figure it out: pretty crazy trying to do everything with a combination of button presses and a tiny, dim LCD screen!\nHere\u0026rsquo;s a two track improvisation, using sounds from my trusty Casio GZ-50M.\n[audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2008/09/cheetr.mp3\"][/audio]\ncheetr.mp3\n"},{"id":80,"href":"/posts/2011-08-17-gamelan-hardcore/","title":"gamelan = hardcore","section":"Blog","content":"Don\u0026rsquo;t listen to this one at all unless you like really hardcore distortion. No, scrub that, just don\u0026rsquo;t listen to this one. Please. (Brownian walks in SuperCollider, samples \u0026amp; fx in Logic Pro.)\n[audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2008/09/gamhum.mp3\"][/audio]\ngamhum.mp3\n"},{"id":81,"href":"/posts/2011-08-15-gender-miking-again/","title":"Gendèr miking again","section":"Blog","content":"\nThe gendèr miking strategy just got simpler again. After some experimentation, it turned out I was getting better results by just whacking all seven mikes in parallel and \u0026lsquo;mixing\u0026rsquo; them with a single 10k resistor. Loads of cross talk, but for this setup it doesn\u0026rsquo;t really matter. The virtual-earth op-amp design wasn\u0026rsquo;t working out, trying to make it run from a single 9v battery was giving me headaches. This is sounding pretty good, perhaps a bit too much percussive thump at the start of the note: need to find a different way of mounting the mikes, at the moment they are just blu-tacked to the casing.\n"},{"id":82,"href":"/posts/2011-08-11-gamelan-impro-sliced-in-supercollider/","title":"Gamelan impro sliced in SuperCollider","section":"Blog","content":"Not sure if this is really going anywhere really, but… a little bit of gendèr and ketipung impro sliced up in SuperCollider:\n[audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2008/09/afrbfr.mp3\"][/audio]\nafrbfr.mp3\n"},{"id":83,"href":"/posts/2011-08-09-max-speech-munged-in-pd/","title":"Max speech munged in Pd","section":"Blog","content":"http://youtu.be/5rCYUlvj2dY\nStill at the point of being a tech demo, but my latest text-to-screech project has moved forward a little. Here you can see speech sounds controlled by Max 5 piped into PureData. In Pd, I\u0026rsquo;m using some old tricks with the \u0026lsquo;freeze\u0026rsquo; function in freeverb plus some pitch shifting to further play with the sound. As a potentially interesting wrinkle, the effects in Pd are turned on and off by the words typed in Max: \u0026lsquo;reverb\u0026rsquo;, \u0026lsquo;freeze\u0026rsquo; etc.\nHmm. Where to go next?\n"},{"id":84,"href":"/posts/2011-08-09-trip-points-one-shot-cap/","title":"trip points one-shot cap","section":"Blog","content":"[soundcloud url=\u0026ldquo;http://api.soundcloud.com/tracks/20785288\"]\n\u0026rsquo;trip points one-shot cap\u0026rsquo; is (yet another) piece inspired by ripped off from alluding to Louis Andriessen\u0026rsquo;s gritty post-minimalist classic \u0026lsquo;Hoketus\u0026rsquo;.\nThere are two main building blocks. The first is… I was rummaging around in my box of old electronics, and found an optical theremin I\u0026rsquo;d built years ago. The IC at the heart of this is a bit of a classic, a Texas Instruments SN76477, a very early chip designed to make sounds for toys and games, also great for musical experimentation.\nThe second part of the track is itself made up of two layers. At the bottom is a two-second slice (ntfot82.aif) of an improvisation made with… well, to tell the truth, I can\u0026rsquo;t remember! An out-of-tune guitar played with a chopstick, I think, but I\u0026rsquo;m not sure what I was processing it through, might have been hardware, might have been software. This short file was then sliced up and remixed in SuperCollider (code below).\nThe final track was composed in Logic 9: no added effects there apart from a bit of fake stereo.\n//SuperCollider code s.boot;\np = \u0026ldquo;/Users/jsimon/Music/tedsound/prosim/nolap_firstofthese/slices/ntfot82.aif\u0026rdquo;; b = Buffer.read(s, p); b = Buffer.read(s, p, bufnum: 0); b.play; //quick check\nb.free; // eventually\n( SynthDef(\\mybuf, { |out, bufnum, sig, rate=1, slices=16, slice=16| var myenv, env, start, len; len = BufFrames.kr(bufnum); start = (len / slices * slice); myenv = Env.linen(0.01, 0.2, 0.1); //attack, sustain, release sig = PlayBuf.ar(2, bufnum, BufRateScale.kr(bufnum) * rate, startPos: start, loop: 1); env = EnvGen.kr(myenv, Impulse.kr(0), doneAction: 2); Out.ar(out, sig * env) }).add; )\n( a = Pbind( \\instrument, \\mybuf, \\slice, Prand((1 .. 16), inf) ); )\na.play;\n( b = Pbind( \\instrument, \\mybuf, \\slice, Pseq((1 .. 16).scramble, inf) ); )\nb.play;\n( c = Pbind( \\instrument, \\mybuf, \\slice, Pseq((1 .. 16).pyramid, inf) ); )\nc.play;\n// this is medium fab // need to get \\freq or something in the synth also // also figger out how buffer number allocation works // could allocate several buffers and switch between?!?\nTempoClock.default.tempo = 160/60;\n( d = Pbind( \\instrument, \\mybuf, \\slice, Pseq((1 .. 16).pyramid(9), 1), // careful pyramid returns all kinds of different length arrays // 136, 256, 271 seems to be the three possibilities // (1 .. 16).pyramid(9).size; -\u0026gt; 256 \\dur, 0.5 ); )\nd.play;\n"},{"id":85,"href":"/posts/2011-08-08-gender-mic-prototype-01/","title":"Gendèr mic prototype 01","section":"Blog","content":" Up to something a bit different today: electronics! Yum. I\u0026rsquo;m building a simple op-amp virtual earth mixer, which I\u0026rsquo;m going to use to combine the signal from seven cheapo tie-pin mics, one for each pair of keys. A few false starts today, bit rusty on this, but now have a simple circuit running from a 9v battery, which is producing really a very good sound indeed from a £3 mic. Off to buy six more of them, then…\n"},{"id":86,"href":"/posts/2011-08-04-happy-me/","title":"Happy Me","section":"Blog","content":"A wee jazz tune which I came up with the other day. If my new wordpress.com blog would let me, I\u0026rsquo;d embed it for playback: but I can\u0026rsquo;t, so here it is on musescore.com.\n"},{"id":87,"href":"/posts/2011-08-04-the-diagram-ought-to-be-the-programm/","title":"The diagram (ought to be) the program","section":"Blog","content":"\n\u0026lsquo;The diagram is the program\u0026rsquo; according to Miller Puckette, creator of Pd and (originally) Max. But sometimes you have to draw the diagram too… :)\n"},{"id":88,"href":"/posts/2011-08-02-routing-text-to-speech-on-the-mac/","title":"Routing text-to-speech on the mac","section":"Blog","content":"http://www.youtube.com/watch?v=3FG_tsG7mI4\nThere are any number of ways of working with the built-in text-to-speech synthesis capabilities on the mac. All of the music programming languages I use - Max, Pd and SuperCollider - offer ways of doing this, and I\u0026rsquo;ve also had great success with controlling the output using AppleScript. The problem is that in every case, the audio itself is actually synthesised by the mac os itself, which means it is not accessible within an audio environment for further processing.\nI was inspired to have another think about this recently by a thread on the SuperCollider list where somebody was trying to do exactly this, by using Jack to route the sound from the mac back into the application for further processing. What I\u0026rsquo;ve started to experiment with is routing the audio into a different application: in the example above, controlling the speech synthesis in Max and passing the audio into Pd. Combined with the facility to pass midi from Max to Pd (easy), I think I can see how I can make a workable and potentially interesting system. But, for now, just proving to myself that it can be done :)\n"},{"id":89,"href":"/posts/2011-08-02-yet-more-text-to-screech/","title":"Yet more text-to-screech","section":"Blog","content":"There\u0026rsquo;s quite a history of musicians and sound artists doing creative things with speech synthesis. One of the best known examples is the Radiohead track Fitter Happier from the album OK Computer, and its not hard to find other cases of commercial artists incorporating this kind of material in tracks.\nVery often this has been done on the mac, which has always had speech synthesis built in. (There\u0026rsquo;s a very interesting anecdote about how speech synthesis came to be included on the very first macs at the personal insistence of Steve Jobs.) A number of years ago - I can\u0026rsquo;t find the links now - there was a small community of composers who were authoring and releasing \u0026rsquo;tracks\u0026rsquo; which consisted of nothing but SimpleText files, which were to be \u0026lsquo;played back\u0026rsquo; using the speech synthesis facility. This kind of thing was more effective back then: the earlier versions of the mac speech system responded in interesting and unpredictable ways to abberrant texts.\nI\u0026rsquo;ve often used this kind of thing in my own work, and I\u0026rsquo;ve coined my own term for it: \u0026rsquo;text-to-screech\u0026rsquo;. Here\u0026rsquo;s an example, this is a track called \u0026lsquo;vifyavif wif yavif-oo\u0026rsquo;, which also forms part of the instrumental piece donkerstraat: [soundcloud url=\u0026ldquo;http://soundcloud.com/tedthetrumpet/vifyavif-wif-yavif-oo\" params=\u0026ldquo;show_comments=true\u0026amp;auto_play=false\u0026amp;color=ff7700\u0026rdquo; width=\u0026ldquo;100%\u0026rdquo; height=\u0026ldquo;81\u0026rdquo; ]\nI\u0026rsquo;ve now started work on another such project. This will be a performance piece, where I will be typing text live: I\u0026rsquo;ve done work along these lines before, but the new twist will be to try to find away to add extra processing to the speech synthesis live, including perhaps sampling and looping. There are some technical problems with doing this on the mac, however… which I\u0026rsquo;ll make the subject of another post.\n"},{"id":90,"href":"/posts/2011-07-29-the-sloans-project/","title":"The Sloans Project","section":"Blog","content":"I saw a great new opera recently, The Sloans Project. Composed by Gareth Williams with a libretto by David Brook, it was set and performed in the historic Sloans Bar and Restaurant. Yes, that\u0026rsquo;ll be opera performed in a pub! The opening scene was a coup de theatre. As the audience milled about in the bar downstairs, the show just started right there, with a couple at the bar bursting into song, soon to be answered by another drunken-looking guy at the bar. After that the audience were invited to process to some of the upstairs rooms, where there were a series of three vignettes, followed by a culminating scene in the ballroom.\nGareth of course is a friend and colleage of mine of old, with his PhD at the RSAMD – sorry, the Royal Conservatoire of Scotland – running more or less in parallel to mine. Recently he\u0026rsquo;s been plowing the operatic furrow consistently and with great success. His musical language is very spare and secure, with a great command of vocal writing. In this piece I was drawn in by the unique staging as much as anything else, but I seemed to detect some new thinking in his approach, particularly in scene two Chopin\u0026rsquo;s Ghosts, which collided separate and uncoordinated music in different keys on the harp and piano in a very creative and effective way.\n"},{"id":91,"href":"/posts/2011-07-26-parkbenchpound/","title":"parkbenchpound","section":"Blog","content":"[soundcloud url=\u0026ldquo;http://api.soundcloud.com/tracks/19798777\"]\nMags and I were enjoying a pleasant evening walk in Maxwell Park, when she had a lucky find: a pound coin sitting on the grass beside a metal park bench. We had some fun sitting in the sun and improvising with the sound of the bench and the coin, which I recorded on my new HTC Wildfire S Android phone. I made the track in Logic using nothing but those sounds: fairly minimal effects, just some pitch shifting and fake stereo. Sort of an urban gamelan thing…\n"},{"id":92,"href":"/posts/2011-07-11-music-and-intellectual-play/","title":"Music and intellectual play","section":"Blog","content":"Next year at the Royal Conservatoire of Scotland I\u0026rsquo;m going to be sharing the teaching of the Teaching Musics of the World module with my colleage Barnaby Brown. I was doing some background reading, having a look at Bonnie C. Wade\u0026rsquo;s \u0026lsquo;Thinking Musically\u0026rsquo;, which is one of the overview volumes in OUPs \u0026lsquo;Global Music Series\u0026rsquo;. This is just an undergrad textbook, but I did stumble upon on a notion which set me thinking, where she discusses \u0026lsquo;intellectual play\u0026rsquo;:\nIntellectual play as well as aesthetic choice are the major factors in an improvisatory South Indian performance practice called rāgamālikā (\u0026ldquo;garland of ragas\u0026rdquo;). Rāgamālikā comprises a progression from one rāga to another, each sufficiently similar that one must listen closely to detect the shift, but sufficiently different that contrast has been achieved. The intellectual play is enhanced when, in vocal rāgamālikā, the names of the new modes are introduced into the text, embedded in clever ways. (p126)\nAs ever, I find comparisons with the practices of other musical cultures illuminating with regard to my own work. There are so many ideas in my pieces: things which are there primarily for intellectual reasons. Which sounds bad and wrong, doesn\u0026rsquo;t it! Describing music as intellectual is a criticism, isn\u0026rsquo;t it? Especially if I were to self-describe my music as intellectual?\n"},{"id":93,"href":"/posts/2011-05-01-liebesgluck-hat-tausend-zungen/","title":"Liebesglück hat tausend Zungen","section":"Blog","content":"This Tuesday 3rd May at 1600 sees the performance of the only piece I have in this year\u0026rsquo;s Plug festival at the RSAMD in Glasgow, Liebesglück hat tausend Zungen – a lied, for soprano and piano. Now, why on earth, you say would anyone in this day and age want to write a lied of all things?! Good question: I\u0026rsquo;m not sure I know the answer. However, the fact is that the unifying theme of this year\u0026rsquo;s festival is deemed to be something called the Glasgow Liederbuch, to which all the composer have been invited to contribute. Which means, two and several bit concerts devoted to new lieder. Written within rather strict guidelines, I have to say, voice and piano only, no electronics, German poetic text from the era… basically, we\u0026rsquo;re not allowed to do anything which Schubert didn\u0026rsquo;t do. (So, eg dying of syphillis and not finishing symphonies is ok, playing inside the piano is not.)\nThere\u0026rsquo;s a .pdf file of the score if anyone is particularly curious to see in what way I\u0026rsquo;ve tackled this rather odd commission. Have I done anything Schubert wouldn\u0026rsquo;t have done? I think so, I think so :)\n"},{"id":94,"href":"/posts/2010-10-06-fm-patch/","title":"fm patch","section":"Blog","content":"Here\u0026rsquo;s a shot of the fm synthesis patch we threw together in PerfTech today;\nAnd here\u0026rsquo;s what it sounds like; [soundcloud url=\u0026ldquo;http://api.soundcloud.com/tracks/5864108\" params=\u0026ldquo;show_comments=true\u0026amp;auto_play=false\u0026amp;color=ff7700\u0026rdquo; width=\u0026ldquo;100%\u0026rdquo; height=\u0026ldquo;81\u0026rdquo; ] Get a copy of the max patch also if you want.\n"},{"id":95,"href":"/posts/2010-06-20-max-5-and-supercollider-using-sc3/","title":"Max 5 and SuperCollider using sc3~","section":"Blog","content":"http://www.youtube.com/watch?v=vCcl7M5-V1s Another way of doing it, using the sc3~ object. I can\u0026rsquo;t quite make up my mind at the moment which is the way forward; this way it looks like you\u0026rsquo;d have to develop your code in SuperCollider, then paste it into Max and hope it still works… have a feeling the OSC bridging method is more generally useful, for instance, could use it with Pd as well. On the other hand, this way it\u0026rsquo;s all together in the one patch in a single program, to run it you don\u0026rsquo;t need SC installed, probably a lot easier to deal with when you come back to it in five years time…\n"},{"id":96,"href":"/posts/2010-06-18-max-5-to-supercollider-using-osc/","title":"Max 5 to SuperCollider using OSC","section":"Blog","content":"http://www.youtube.com/watch?v=1QhG4cpS9ik\nUpdated # I guess it\u0026rsquo;s just possible some people might not get what\u0026rsquo;s going on here :) SuperCollider is a very powerful text-based programming language for sound. If you know what you\u0026rsquo;re doing, then with just a couple of lines of code you can create really fascinating sounds and textures, even entire compositions; see for instance sc140, an album where each piece is created using just a twitter-long 140 characters of code.\nUnfortunately, I don\u0026rsquo;t know what I\u0026rsquo;m doing; my mind doesn\u0026rsquo;t seem to work logically enough to really do computer programming properly! Enter the other half of the equation, Max 5 (or Max/MSP as it used to be known). This is a graphical programming language, which allows you to make stuff happen just by plugging things together on the screen.\nI\u0026rsquo;ve got quite good at Max, and sometimes managed to make quite interesting sounds in SuperCollider. I found the missing link between these two on a great blog posting by Fredrik Olofsson. It\u0026rsquo;s a way of using a so-called \u0026lsquo;quark\u0026rsquo;, a type of extension to SuperCollider, to send OSC (Open Sound Control) messages from Max to SC. So, what I\u0026rsquo;m happy to have found here is an easy way to attach knobs to these hard-to-get-at text based sounds. The next step from here will be controlling SC using external midi/bluetooth/whatever hardware, again via Max.\n"},{"id":97,"href":"/posts/2010-05-20-fimpac-day-1/","title":"FIMPaC day 1","section":"Blog","content":"So here I am at the Forum for Innovation in Music Production and Composition at Leeds College of Music. It\u0026rsquo;s been a while since I\u0026rsquo;ve attended a conference, but I\u0026rsquo;m getting back into the swing of it. It\u0026rsquo;s hardly coalmining; nevertheless, it\u0026rsquo;s quite tiring to sit still all day listening to a long series of what can be quite dense and complicated presentations.\nThe subject matter for this conference at least is consistently up my street. Here\u0026rsquo;s a quick outline of the things people have been talking about, these are not the paper titles, but rather my quick summaries;\nJulian Brook on the role of and status of the person operating the mixing desk in ea music Martin Blain on the MMULe laptop ensemble in Manchester (must find out about an article by Michael Kirkby which he referred to, on acting and non-acting?) Adam Stansbie building up and then comprehensively knocking down some dubious philosophical ideas (Godlovitch) which have been proposed around performance in ea music some, um, perhaps not entirely convincing comparisons between so-called \u0026lsquo;avant-rock\u0026rsquo; and \u0026rsquo;experimental\u0026rsquo; musics from Chris Ruffoni an entertaining and difficult paper from Robert Wilsmore on music sampling, full of clever postmodern confusions, most notably his so called \u0026lsquo;Wilsmore Symphony No 2\u0026rsquo;, where he proposed the thought experiment of taking Beethoven\u0026rsquo;s Symphony No 2, scoring out Beethoven\u0026rsquo;s name and putting his on it instead Jon Aveyard comparing practices in binaural audio to the cinematic notion of the \u0026lsquo;point of view\u0026rsquo; (interesting, ideas for a piece in there, also some nice demo\u0026rsquo;s of different kinds of POV shot from Goodfellas and The Lady in the Lake (1947) Robert Ratcliffe showing some of his complex and brilliant mashups of, like, Aphex Twin and Berio?!? I now remember meeting Robert at a previous concert, his work is really, really great, clear, entertaining, naughty Mark Marrington giving a thoughtful survey of the state of the modern digital audio workstation, and how it informs the work of his composing students Rob Godman talking about live-ness and stage presence, with reference to his piece Duel for piano and sound projection Oh, yes and we had Jazzie B this morning, for, well, a keynote speech, but really mostly a question and answer session about his wide range of experiences as a music producer. Also met Frank Millward, who it turns out is doing a project in Glasgow at the moment which sounds right up my street, looking forward to hooking up with him again. Also caught up with Jane Anthony; I did a piece a few years ago for her Leeds Lieder+ festival, talking about me coming down for a talk, maybe even doing the whole song cycle down there. Also met a couple of my ex-students. Also, just had a great bowl of satay noodles. Enough for one day, I think.\n"},{"id":98,"href":"/posts/2010-04-27-etude-poeme-pour-pianiste-recitant/","title":"Étude-Poème pour Pianiste Récitant","section":"Blog","content":"The programme note for my latest piece Étude-Poème pour Pianiste Récitant, being performed this evening at 1830 by Silviya Mihaylova.\n\u0026lsquo;So, here’s the idea; a piano étude where the pianist speaks to the audience, playing along with what she is saying. This idea has several things going for it, for one, hopefully nobody else will have hit on the selfsame thing. Also… here’s what it says in the Oxford Companion to Music, under ‘étude’;\n‘The essence of the genre is revealed in the title of one of J. B. Cramer’s sets, “Dulce et utile” (“sweet and useful”), as distinct from an ‘exercise’ which is merely useful.’\nAnd that seems to me to be right, an étude should be entertaining as well as a technical challenge. Big drawback, of course, is that far from being original it’s really far too much like that Tom Johnson piece ‘Failing: A Very Difficult Piece For String Bass’. Oh well. Too bad.\n"},{"id":99,"href":"/posts/2010-04-10-bighexhambook/","title":"BigHexhamBook","section":"Blog","content":"Having some free time over the Easter break, and in preparation for taking part in a performance of Cage\u0026rsquo;s Musicircus at Tramway on 30 May, I\u0026rsquo;ve been playing with the Lexicon MPX 100 effects unit which Allan Neave gave me, feeding it back into itself, which works particularly nicely on the pitch-shift-plus-delay patches. At the same time I\u0026rsquo;ve been working on a Max patch which drifts five-note chords gradually through a modulating set of hexatonic regions, so… without really meaning to, I ended up putting together a sort of ambient track combing the two;\n[soundcloud width=\u0026ldquo;100%\u0026rdquo; height=\u0026ldquo;81\u0026rdquo; params=\u0026ldquo;show_comments=true\u0026amp;auto_play=false\u0026amp;color=ff7700\u0026rdquo; url=\u0026ldquo;http://soundcloud.com/tedthetrumpet/bighexhambook\"] BigHexhamBook by tedthetrumpet@\nThe Max patch;\n"},{"id":100,"href":"/posts/2010-02-01-maxmsp-to-logic/","title":"Max/MSP to Logic","section":"Blog","content":"This is the sort of thing where there\u0026rsquo;s probably a video out there already explaining it, but as I ended up figuring it out myself anyway, I thought I might as well make my own video… This is how to send midi information from Max/MSP to Logic Pro, in particular how to use Max to control the automation parameters of a softsynth running in Logic. Probably best to watch these fullscreeen; http://youtu.be/8nHpYZkgi1A http://youtu.be/mA3-vTIpkXQ\n"},{"id":101,"href":"/posts/2009-10-22-certain-assumptions-at-artmusfair/","title":"‘certain assumptions’ at ArtMusFair","section":"Blog","content":"ARTMUSFAIR is… well, I guess you could describe it as a trade fair for contemporary music (stop giggling) which this year is happening in Glasgow, Thur 29 Oct to Sun 1 Nov. I\u0026rsquo;ve got two things confirmed and a third in the pipeline.\nFirst up is a new piece certain assumptions, which was accepted in a call for scores by the Red Note Ensemble. It\u0026rsquo;s for alto flute, horn, marimba, cello and \u0026rsquo;tape\u0026rsquo;, with the latter part composed using a patch I made at the pd bootcamp in Wales earlier this year. Here\u0026rsquo;s the \u0026lsquo;programme note\u0026rsquo;;\n\u0026lsquo;When you go to the doctor you assume that he will care for you in his normal compassionate way, ultimately finding the solution to your ailments. Why else would you go?\nOn your last trip to the grocery store did you assume the food was free from bacteria? I bet you did, otherwise you would find somewhere else to shop; that is if you lived through the bacterial infection.\nAs you can see sometimes assumptions help us relieve potential anxiety. They can be very useful ways of diverting stress but unfortunately even the white knight puts on a black hat once in a while.\u0026rsquo; (http://bit.ly/LFxW8)\nAccording to the information I have \u0026rsquo;the performance is scheduled to begin at 10:30pm on 30th October 2009, in the bar attached to the Millennium Hotel on George Square, Glasgow. The performance will be informal, amplified and compered.\u0026rsquo;\nThen, on the Saturday morning at about 0900 we are planning a performance of CIRCULARTHING and other works by the long-lost Society for High Art Music. To complete a trilogy of van der Walt, I\u0026rsquo;m also trying to persuade them to let me give the first performance of my soon-to-be-notorious \u0026lsquo;Music Is Not Sound\u0026rsquo; lecture.\n"},{"id":102,"href":"/posts/2009-09-23-first-steps-in-maxmsp/","title":"First steps in Max/MSP","section":"Blog","content":"Nothing earth-shaking here, just the very first Max/MSP patch I built with my Performance Technology students today.\nhttp://www.youtube.com/watch?v=ptgQIun-H70\n"},{"id":103,"href":"/posts/2009-09-11-sibelius-versus-tilde-updated/","title":"Sibelius versus tilde – updated","section":"Blog","content":"A long-standing frustration of mine is the way the music notation package Sibelius handles the \u0026rsquo;tilde\u0026rsquo; sign ~ in text. As a sort of clever bodge or hack, it is used to hide midi messages, so that a control change for example can be put in the score as \u0026lsquo;~C64,127\u0026rsquo;, but won\u0026rsquo;t print out.\nHowever, I\u0026rsquo;m of the frequent habit of using the ~ sign to mean \u0026lsquo;approximately\u0026rsquo;; I\u0026rsquo;d love to be able to mark a pause, for instance as \u0026lsquo;~45 seconds\u0026rsquo;, meaning roughly 45 seconds, but when you do that the text gets hidden.\nToday I thought I\u0026rsquo;d found a hack for the hack, a workaround for the workaround. In the character palette on the mac, I found something called the \u0026rsquo;tilde operator\u0026rsquo; character under the maths category which looks exactly the same, but as it isn\u0026rsquo;t an ascii tilde, Sibelius doesn\u0026rsquo;t hide the text; However, something else kind of strange happens. When I\u0026rsquo;m editing the text string in Sibelius the character seems to display correctly, but when I come out of edit mode it gets displayed as a grey box; So, still impossible to use a ~ character in text anywhere in Sibelius without the text being hidden. How frustrating.\nUpdate\nFollowing some helpful remarks on the Yahoo! Sibelius group and in my blog comments, this has been cleared up a bit. The ~ character isn\u0026rsquo;t in the Arial font, but inserting it as Symbol font works fine; this seems to kind of happen automagically in Word and Pages and not Sibelius, but that\u0026rsquo;s fine and easy to fix.\nThere\u0026rsquo;s also been a suggestion that I shouldn\u0026rsquo;t use this symbol as it wouldn\u0026rsquo;t be clear to musicians. On looking into this is discover that ~ as an abbreviation for \u0026lsquo;approximately\u0026rsquo; is not as widespread as I thought it was, although for me it\u0026rsquo;s an everyday thing. Oh well; being unclear to musicians is all part of the game anyway.\n"},{"id":104,"href":"/posts/2009-09-04-pd-bootcamp-at-the-rwcmd/","title":"Pd Bootcamp at the RWCMD","section":"Blog","content":"All week I\u0026rsquo;ve been on a PureData course at the Royal Welsh College of Music and Drama, with Simon Kilshaw. PureData, or Pd, is a free and open source graphical programming language for music and video; in plain language, a system allows one to plug together a series of graphical objects on a screen in order to create an original work of digital art.\nPd is closely allied with another very similar language, Max/MSP, both having in fact been initiated by the same programmer, Miller Puckette. I\u0026rsquo;ve been working with and teaching a Max/MSP course for several years now; so why study Pd? Max/MSP is in many ways a much slicker and more fully developed environment, significantly easier to use, with clear documentation and tutorials, many higher level objects built in, and a large community of users. By contrast, coming to Pd from Max feels like a step back in time; the user interface seems clunky, many basic objects seem to be missing, the documentation is by comparison chaotic, and overall it feels like a poor relation.\nWell, poor; yes exactly! You would be if you had to buy Max/MSP at the full commercial going rate of $699, and the \u0026lsquo;price point\u0026rsquo; of Pd is undoubtably a serious attraction. More importantly, perhaps, the open source nature of Pd creates a different kind of community, one where it is perhaps easier for creative artists to own and share their digital works without being encumbered by licencing considerations.\nThe course here has been quite a full-on experience. Simon and his students at RWCMD seem to have a programming style which is extremely fast and hacky, driving straight at getting musical results from the software without much concern for neatness or elegance. It works; most of the week we\u0026rsquo;ve been following along behind Simon click-by-click as he more or less improvised patches before our eyes. Graphical languages are great for this kind of very rapid prototyping and developing of ideas, although I found that for my style of working I liked to go a little bit slower and think through what I was doing a little more.\nOver the last two days we\u0026rsquo;ve also seen some of the work of one of the graduates here, Tristan Evans, including a very impressive piece for piano and Pd called \u0026lsquo;Takeover\u0026rsquo;. Tomorrow, we\u0026rsquo;re scheduled to put together a collaborative performance using a rather remarkable internet-based version of Pd, netpd; if all goes according to plan you should be able to watch and hear us all performing live using this url at 1500 GMT+1 (that\u0026rsquo;s three o\u0026rsquo;clock UK time).\nI\u0026rsquo;ll (maybe) be performing on the patch above. For those who are interested, this uses nothing which is not in Pd-extended (I hope!). The guts of the sound are four Karplus-Strong \u0026lsquo;pluck\u0026rsquo; synths, with the delay lengths changing at random to produce glissando effects. These gestures are fed into an instance of freeverb, where the reverb tail can be frozen; while the tail is frozen, a pitch shifter patch is used to move this sound around in interesting ways. The klang gestures are either triggered manually, or by a randomised metronome, which can be set to the rather ridiculous value of 25 ms to produce an insane cascade of stringy sounds.\n"},{"id":105,"href":"/posts/2009-09-02-jazz-in-the-closet/","title":"Jazz in the closet","section":"Blog","content":"\nKeeping jazz where it belongs - in the closet :)\n"},{"id":106,"href":"/posts/2009-09-02-yellowpuncher/","title":"yellowpuncher","section":"Blog","content":"http://www.youtube.com/watch?v=jFvzKT-GeIc\nWell, it\u0026rsquo;s a start; learning the basics of GEM in Pd. And, whoever would have thought that the quicktime midi synth on the mac had that \u0026lsquo;Punch\u0026rsquo; sound hidden in one of it\u0026rsquo;s alternate banks :)\n"},{"id":107,"href":"/posts/2009-08-29-text-to-screech-work-in-progress/","title":"text-to-screech work in progress","section":"Blog","content":"I\u0026rsquo;m working on a new piece towards ARTMUSFAIR/2009, for flute, horn, cello, marimba and \u0026rsquo;tape\u0026rsquo;; this is me working towards the latter, the fixed audio part of the piece. Up to my usual text-to-screech tricks here; this shows some of the tools and methods I use to put things like this together.\n[vimeo 6326582]\n(If you go to the original on vimeo you can watch it pretty much full desktop size.)\n"},{"id":108,"href":"/posts/2009-04-15-glasgow-sequenza-xvii-exercise-for-trombone/","title":"Glasgow Sequenza XVII – ‘Exercise’ for Trombone","section":"Blog","content":"This years Plug 2009 festival of new music at the RSAMD starts soon, 27 April - 1 May. One of the features this year is a new set of \u0026lsquo;Glasgow\u0026rsquo; sequenzas, written variously by students and staff and interspersed among larger programme items. Mine is for trombone and, between myself and Head of Composition Gordon McPherson, we\u0026rsquo;ve cooked up a plan to, um, kill a trombonist? Here\u0026rsquo;s my description from the score;\n\u0026lsquo;Over the course of an extended period of time (30-60 minutes) the trombonist is asked to play a \u0026lsquo;virtuosic\u0026rsquo; passage in alternation with vigorous bouts of physical exercise. The piece becomes harder to execute as it progresses; not through any development in the music, but through the physical deterioration of the player. At intervals during the performance we hear a tireless computer rendition of the piece as it \u0026lsquo;ought\u0026rsquo; to be.\u0026rsquo;\nSo we\u0026rsquo;ve got Davur Magnussen, the brilliant new young principal trombone of the RSNO running on a treadmill over the course of an hour, whilst attempting to play \u0026lsquo;virtuosic\u0026rsquo; material of one sort or another in competition with the computer. Should be fun! (Well, not so much fun for Davur, perhaps :) Draft version of the score available as pdf.\n"},{"id":109,"href":"/posts/2009-04-08-musescore/","title":"MuseScore","section":"Blog","content":"I\u0026rsquo;m quite excited today to discover a free/open-source music notation program I hadn\u0026rsquo;t previously heard of, MuseScore. (That I hadn\u0026rsquo;t heard of it probably has something to do with the fact that they\u0026rsquo;ve only just released a mac binary.) Very early days so far, but already I\u0026rsquo;m very excited to see the beginnings of what could be a foss alternative to Sibelius and Finale, something which I think the world badly needs. I had a play with it; it\u0026rsquo;s ok, got used to the note entry and editing interface quite quickly, kind of like a cross between Sib and Fin in the way it works. Didn\u0026rsquo;t take long to notate the gamelan tune I heard in my dream this morning, although I could have done with a custom key signature;\nI was able to export it as a midi file, which had some small problems, and also as .xml which, again after a bit of hacking I was able to open very nicely in Sibelius. Now, if I was dead pure rich and that, I\u0026rsquo;d give these guys a bunch of money to really develop this!\n"},{"id":110,"href":"/posts/2009-03-16-pictures-from-bare-wires/","title":"Pictures from Bare Wires","section":"Blog","content":"[slideshow]\n(Pics by Tamara Polajnar)\n"},{"id":111,"href":"/posts/2009-03-13-bare-wires-in-the-skinny/","title":"Bare Wires in the Skinny","section":"Blog","content":"Nice piece on \u0026lsquo;Bare Wires\u0026rsquo; by Clare Sinclair in the Skinny;\n\u0026lsquo;The lines between technology and the arts are blurring at an astronomical pace: the latest laptops and computers position themselves not only as tools for business, but as home entertainment centres where anything seems possible.\nJ. Simon van der Walt, performing as part of the Cryptic Nights season, parallels this revolution yet takes it back to the \u0026lsquo;Bare Wires\u0026rsquo;. As Edward \u0026lsquo;Teddy\u0026rsquo; Edwards and the Electr-O-Chromatic orchestra, he presents and electronic symphony of music and performance.\nVan der Walt\u0026rsquo;s imagination takes us on a technologically devised musical jourrney with improvisation, composition and electro-junk. His passion as a performer, actor, director and composer is apparent, and he strives to blend musicality, innovation and theatricality into one.\nLuckily, Cryptic\u0026rsquo;s creative drive lies in a similar field, making the Cryptic Nights season a perfect match for the composer. He arrestingly combines his \u0026ldquo;creative misuse of technology\u0026rdquo;, such as text-to-screech (the warping of standard computer text-to-speech software), with reverting back to his childhood use of electronic junk as instruments. This piece could reinvent the way we experience music, and its place in a modern society. The electronic age is vibrantly creative, and with \u0026lsquo;Bare Wires\u0026rsquo; the performing arts are keeping pace.\u0026rsquo;\n"},{"id":112,"href":"/posts/2009-02-22-cynthcart/","title":"cynthcart","section":"Blog","content":"Got hold of a loan of a very cool instrument to use in the show;\nYup, it\u0026rsquo;s a cynthcart, a Commodore 64 hacked up to play as a synth! Tried it out in rehearsal today, works great. (Thanks to Col for the loan.)\n"},{"id":113,"href":"/posts/2009-02-21-plan-for-the-show-version-01/","title":"Plan for the show, version 01","section":"Blog","content":"\n"},{"id":114,"href":"/posts/2009-02-21-plan-for-the-show-version-02/","title":"Plan for the show, version 02","section":"Blog","content":" Well, that worked out easily enough. If the longer numbers are in the region of five mins, I reckon I can just about bring that in at 45 mins.\nAlso working on a list of instruments, looks like twenty-two different bits of gear, including laptops, effects units and conventional instruments.\n"},{"id":115,"href":"/posts/2009-02-20-slipping-away/","title":"Slipping Away","section":"Blog","content":"Driving work the other morning, I wrote this waltz in my head;\nIt\u0026rsquo;s called \u0026lsquo;Slipping Away\u0026rsquo; because, as you might have noticed, each time it repeats it accidentally slides down a semitone; like the last slush of winter on a window pane, or someone slowly, gently, dying\u0026hellip;\nI think I\u0026rsquo;ll use it in the show on March 5th. Which now, finally has a fourth player! And, I got a loan the other day of an *extremely* cool instrument to use in the show, more details to follow.\n"},{"id":116,"href":"/posts/2009-02-15-ed-bends-yamaha/","title":"Ed bends Yamaha","section":"Blog","content":"I was round at Eddie\u0026rsquo;s house the other day, and we had a go at circuit bending an old Yamaha RX17 drum machine;\nThis is pretty standard stuff, a well-known bend linking pins 4 and 12 of IC 116. After some experimentation, we decided on a 100k log pot with a 1k resistor in series. Ed is a bit iffy about the whole idea of circuit-bending, kind of goes against the grain for someone who was trained in electronic engineering! But we had fun - going to use this in the show on March 5th.\n"},{"id":117,"href":"/posts/2008-12-22-ted-edwards-classic/","title":"Ted Edwards classic","section":"Blog","content":"I\u0026rsquo;ve finally managed to persuade Ted to let me post some of the amazing back catalog he\u0026rsquo;s built up over the years. Below is a piece called \u0026lsquo;slacion\u0026rsquo; which he did \u0026lsquo;sometime in the late 70s\u0026rsquo;, using an adapted version of the PE Minisonic synth plus tape loops plus a spring reverb. The video is also by Ted, a recent digital remix of \u0026lsquo;some old Betamax that\u0026rsquo;s up in the loft\u0026rsquo;. I can\u0026rsquo;t wait to find out what else he has up there… [youtube=http://www.youtube.com/watch?v=wrJ3cSXfiqY\u0026amp;hl=en\u0026amp;fs=1\u0026amp;rel=0]\n"},{"id":118,"href":"/posts/2008-12-16-loudcoding/","title":"Loudcoding?","section":"Blog","content":"Managing to do the same kind of thing now in SuperCollider, speaking one word at a time, which kind of makes more sense in this context; loudcoding?\n[youtube=http://www.youtube.com/watch?v=AG8hMLAXs_U\u0026amp;hl=en\u0026amp;fs=1\u0026amp;rel=0]\n(Amazed at getting this to work, actually. I\u0026rsquo;m *so* not a programmer!)\n"},{"id":119,"href":"/posts/2008-12-04-more-text-to-screech/","title":"More text to screech","section":"Blog","content":"Updated version of the Bare Wires text interface;\n[youtube=http://www.youtube.com/watch?v=Pi9olQyxfzE\u0026amp;hl=en\u0026amp;fs=1\u0026amp;rel=0]\n"},{"id":120,"href":"/posts/2008-11-29-bare-wires-text-to-screech/","title":"Bare Wires – text to screech","section":"Blog","content":"Hers is a very early and approximate proof-of-concept video of a possible text-to-screech interface for \u0026lsquo;Bare Wires\u0026rsquo;;\n[youtube=http://www.youtube.com/watch?v=Npii4-3awcQ\u0026amp;hl=en\u0026amp;fs=1\u0026amp;rel=0]\nThe idea is to have a laptop and screen onstage, visible to the audience. The setup is used by various performers during the piece, in various ways; to address the audience, or to direct an improvisation, ask questions, tell a story… anything, really.\n\u0026rsquo;text-to-screech\u0026rsquo; is my coining for taking familiar text-to-speak technology built into many modern computers, and mangle it, creatively misuse it. The most extensive project I have done along these lines was a commission in 2005 for an online piece for Paragon, which is unfortunately not up any more. A similar strategy was used in \u0026lsquo;The Other Other Hand\u0026rsquo;, where creatively edited machine speech was used to represent the voice of the Edwardian composer C. Hubert H. Parry.\nThe interface shown above is done in Max/MSP, using the built-in voices on a mac. The first aim was to program it so that it would speak each word immediately after it was typed, which was relatively simple to achieve. In addtition, when an \u0026lsquo;x\u0026rsquo; is typed in a word, the partcular voice used changes, typing \u0026lsquo;u\u0026rsquo; or \u0026lsquo;v\u0026rsquo; subtly affects the rate and pitch of the voice. For the next iteration, I want to try the effect of having it speak the word then display it; also to munge the spoken text more drastically, perhaps mutliple voices speaking, perhaps a more clearly pitched approach, perhaps looping a word, so that the result is more \u0026lsquo;musical\u0026rsquo;.\nThe demo video above fakes up very roughly what it might be like if one performer types up instructions to the others, and then addresses the audience. Another idea I have been playing with is a game whereby the performers are instructed, for instance, to make some sort of distinctive gesture every time an \u0026lsquo;a\u0026rsquo; is typed, and no to obey any other instructions given. So, for instance, the audience sees the performers being told \u0026lsquo;play a note\u0026rsquo;. The performers actually respond to the two \u0026lsquo;a\u0026rsquo;s in the sentence by throwing a book to the floor, which is a the prearranged (invisible) instruction. Then the gag is blown by by one of the performers explaining onscreen what is going on. Then another performer changes the rules… etc etc.\n(Another, umm, visual/performative reference here is to livecoding, where an artist improvises live onscreen with a computer programming language to produce music and/or visuals, some nice examples here. I\u0026rsquo;ve been doing some experimenting in that direction myself using SuperCollider, which can also, as it happens, do text-to-speech. Watch this space…)\n"},{"id":121,"href":"/posts/2008-11-20-the-whirlies-success/","title":"The Whirlies – success!","section":"Blog","content":"The performance of The Whirlies the other night was a bit of a stunning success. Good audience, including the arts editor of the Herald, Keith Bruce, who seemed to really get the piece;\n\u0026lsquo;The new music came from J Simon van der Walt, whose The Whirlies pitted his own prepared multiphonic scrabbling with table-top banjo ukulele and electronic gizmos against lush concert-orchestra strings - a collision only enhanced by the shattering of a glass behind the bar.\nThere was some theatre, too, in his intensity and the swaying of the cellists, in as perfect a musical encapsulation of the East Kilbride road system as I ever expect to hear.\u0026rsquo;\nThe East Kilbride Mail also wrote up the piece enthusiastically, and even did one of those celebrity twenty question interviews (click on the thumbnails to see full size scans);\n"},{"id":122,"href":"/posts/2008-10-22-bare-wires/","title":"Bare Wires","section":"Blog","content":"I\u0026rsquo;m putting in a proposal to Cryptic Nights to do a show called, to give it its full title, Ted Edwards proudly presents Bare Wires - Live in concert or just Bare Wires for short. Below I\u0026rsquo;ve gathered together in one place some relevant video and other documentation;\n\u0026lsquo;The Other Other Hand\u0026rsquo; is pretty much fully documented from initial ideas to final performance at workingtitle08.blogspot.com - the best place to start is probably the three-minute preview video at the top of that page, also available on YouTube. A fully edited 80 minute edited video of the complete show is online here.\nAlso on my YouTube page are two videos which show one of the starting points for the Ted Edwards project; my fortuitous discovery of several pieces of interesting retro music gear discarded in the street near where I live, in this case a Novation BassStation synth.\nFurther down this blog you will find some information about the forthcoming performance of a new commission The Whirlies for the Scottish Philharmonic Orchestra at Òran Mór on November 17th. This will be the first show in which I myself appear in my Ted Edwards role; below you will find a photo and description of the gear to be used, plus a demo recording of the piece.\nFor a thorough background on my work for the last twenty years or so, go to jsimonvanderwalt.com - particularly relevant to Bare Wires might be the Openings series of works, such as CIRCULARTHING, the score for which is shortly to be published in Notations 21, a followup book to John Cage\u0026rsquo;s seminal 1968 collection of graphic scores \u0026lsquo;Notations\u0026rsquo;.\n"},{"id":123,"href":"/posts/2008-10-03-the-whirlies-finished/","title":"The Whirlies – finished","section":"Blog","content":"The performance of \u0026lsquo;The Whirlies\u0026rsquo; is coming up very soon;\nThe Whirlies by J. Simon van der Walt A new piece for strings and electro-junk improviser, inspired by the roundabouts of East Kilbride\nScottish Philharmonic Orchestra Cond Peter Cynfryn Jones Solist Edward \u0026lsquo;Teddy\u0026rsquo; Edwards\nÒran Mór (Byre\u0026rsquo;s Road, Glasgow) Monday 17 Nov 2008 Doors open at 1715, Concert begins at 1815 £10 includes cocktail and canapés 0141 357 6200\nAlso featuring Vaughan Williams A Lark Ascending Debussy Danses Sacré et Profane Respighi Il Tramonto\nHere\u0026rsquo;s a wee snippet of the piece, midi strings, but the impro material is for real:\n[audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2008/09/whirlies-d-ex.mp3\"][/audio]\nwhirlies-d-ex.mp3\nComposer\u0026rsquo;s note\n\u0026ldquo;What is East Kilbride famous for? I\u0026rsquo;m not entirely sure how most people would answer that question! For myself, although I\u0026rsquo;m not exactly Scottish born and bred, there is a big chunk of me which is \u0026lsquo;from\u0026rsquo; East Kilbride; I spent two highly formative periods of my life there, during my primary school years, and again for the last couple of years of high school before university. And one of the things which always sticks in my head about East Kilbride is… roundabouts! Being one of those 60\u0026rsquo;s new towns, it has an elaborate road plan, with sweeping dual carriageways carefully separated from winding dead-end closes; the kind of town where you can see the house you\u0026rsquo;re trying to get to, but there seems to be no way of actually getting there…\nThe biggest roundabout in East Kilbride is known to most residents by name; \u0026lsquo;The Whirlies\u0026rsquo;. In recent times it\u0026rsquo;s been rather travestied by the addition of traffic lights, but in it\u0026rsquo;s heyday it was a madness of a junction, roads spiralling off in every direction…\nOf course, a piece of music can\u0026rsquo;t really be about a roundabout. More than that, this is a reminiscence of my teenage years, when I first started to become seriously interested in music. There were two strands to this. Firstly, I was starting to branch out from my Father\u0026rsquo;s transcendental but admittedly rather limited listening diet of Bach, Wagner, and, er nothing else, to explore the delights of jazz, experimental rock music, Stravinsky, and Bartók. My second way into music was through the soldering iron, literally getting my fingers burnt hacking together home-made noisemakers using transistors salvaged from broken hi-fi sets and the like.\nThe piece also forms a trailer of sorts for a forthcoming project provisionally entitled \u0026lsquo;The Ted Edwards Electr-O-Matic Orchestra\u0026rsquo;, or something like that.\nHere\u0026rsquo;s the setup I\u0026rsquo;m using for the electro-junk impro;\nThat\u0026rsquo;s my grandfather\u0026rsquo;s old banjo-ukulele through a pickup to a genuine original Realistic Electronic Reverb (with added feedback loop), through a mixer to keep the levels under control. No live computer processing! (but a tiny amount of reverb added in the demo to make it \u0026lsquo;sit\u0026rsquo; with the dodgy washy midi strings.)\nI hope you like my new direction :|\n"},{"id":124,"href":"/posts/2008-09-26-no-bands/","title":"No bands","section":"Blog","content":"According to MySpace Music, there are no bands within 100 miles of Glasgow;\nSeems a bit of a shame, really. Anybody feel like starting a band?\n"},{"id":125,"href":"/posts/2008-09-22-lovely-music-for-piano-and-striking-clock/","title":"Lovely music for piano and striking clock","section":"Blog","content":"[audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2008/09/reveal_chime.mp3\u0026rdquo;][/audio]\nreveal_chime.mp3\nSome music I\u0026rsquo;m working on for a puppet show…\n"},{"id":126,"href":"/posts/2008-08-16-the-whirlies-early-sketches/","title":"The Whirlies – early sketches","section":"Blog","content":"I have a commission for another piece from the Scottish Philharmonic Orchestra, for a concert at Òran Mór in Glasgow on 17 November. It\u0026rsquo;s going to be called \u0026lsquo;The Whirlies\u0026rsquo;, which is a famous roundabout in East Kilbride; to be the first movement of a suite dedicated to the, er, roundabouts of East Kilbride!\nThe piece is essentially for strings, but - and I haven\u0026rsquo;t exactly told them this yet - I intend to turn up and do some live electro-junk impro along with the piece as well.\nTwo bits of string material so far;\n[audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2021/06/failing-fly.mp3\"][/audio] failing fly.mp3\n[audio src=\u0026ldquo;https://tedthetrumpet.files.wordpress.com/2021/06/failing-fly-var.mp3\"][/audio] failing fly var.mp3\n"},{"id":127,"href":"/docs/works/2008-02-29-scam/","title":"The Society for Classical and Authentic Music","section":"Works","content":"\u0026lt; previous piece next piece \u0026gt;\nVideo # (Video coming soon, one day, never, if I ever get round to editing it…)\n3/11/06 for six oboes, six bassoons, two ghettoblasters and conductor # Composer\u0026rsquo;s note # \u0026lsquo;The Society for Classical and Ancient Music is the ritual court orchestra of the independent island principality of San Serif. The oboe and bassoon were brought to the island by Portuguese traders in the C17th; in the subsequent centuries a unique playing tradition has evolved, a syncretic blend of cargo-cult findings and the imitated voices of ancestral spirits. The RSAMD are proud to be able to present this rarely-heard music in a concert setting, and would ask that the audience respect the fact that, for the players, today\u0026rsquo;s performance will be a religious ceremony as well as a concert.\u0026rsquo;\n(There is also a more complete version (.pdf, 44KB) of the composer\u0026rsquo;s note.)\nNotes # This piece came about as a result of an invitation to write for the BBC Scottish Symphony Orchestra\u0026rsquo;s Reed On! event in Nov 06; they were looking for a piece for six oboes and six bassoons, to go alongside a (fairly odd it has to be said) programme of music for double reeds.\nSCAM revisits territory first explored in my earlier street-band project The Society for High Art Music. It is almost entirely put together from bits of existing musical material drawn from my Openings series, assembled in rehearsal into a quasi-theatrical whole.\nFirst performed 3/11/06 by Fraser MacAulay, Sarah Cruickshank, Lynsey Bolton, Arlene Cochrane and Siobhan Donnelly (oboes) and Vic Scott, Fraser Gordon, Eanna Monaghan, Anna Mary Lynch and Graeme Brown (bassoons), with the composer as conductor/ghettoblasters/kazoo. Second performance by the same personnel 2/3/07, with the kazoo part replaced by a schmael.\nDuration ~10'\n"},{"id":128,"href":"/posts/2006-05-04-great-review-for-schaduwee/","title":"Great review for ‘Schaduwee’","section":"Blog","content":"Well, Gareth and I got a really excellent review for our concert last night from Michael Tumelty in the Glasgow Herald;\n\u0026lsquo;Let\u0026rsquo;s not mess about. Never mind technical shortcomings, rough edges, the fractured tenor who was clearly in discomfort. Last night\u0026rsquo;s offering by RSAMD students in the academy\u0026rsquo;s festival of new music, Plug, gets five stars for the originality of creative thought that flowed from student composers Simon van der Walt and Gareth Williams into two new works for theatrical performance.\nIn another era, van der Walt\u0026rsquo;s Schaduwee would have been called a song cycle. This creation, for soprano, four bassoons, piano, electronics, kazoo, projected images and some horseplay (I\u0026rsquo;ve never seen the pianist hilariously heave out the innards of a prepared piano as part of a piece) was something else, though there were enough Malherian devices to give a hook into the familiar. The piece, a musical, literary and theatrical questioning of language, was abundant with ideas, arcane and mundane, but was dazzlingly performed by stratospheric soprano Alexa Mason and her team of intrumentalists.\nGareth Williams\u0026rsquo; one-act boxing opera, Love in the Blue Corner, is like nothing else I\u0026rsquo;ve seen in a theatre. It turns its subject inside out. There is only one boxer. He\u0026rsquo;s a loser and he dies, beaten to a pulp. He stands, silent and still in the read-lit centre of the ring, while a make-up artist daubs him with the sweat, bruises, cuts, fractures and wounds that leave him wrecked. The action of the match is in Williams\u0026rsquo;s postminimalist, postmodern music, belted out by the ensemble, and given voice by the trainer, who exhorts his stubborn failure of a protege to move, jab, dance, persist.\nIt was a heartbreaking tragedy in a mind expanding night from the students.\u0026rsquo;\n"},{"id":129,"href":"/docs/works/works-section/","title":"Works Section","section":"Works","content":" Section # Section renders pages in section as definition list, using title and description. Optional param summary can be used to show or hide page summary\nExample # {{\u0026lt; section [summary] \u0026gt;}} First Page First page # Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Second Page Second Page # Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. "},{"id":130,"href":"/docs/works/works-section/first-page/","title":"First Page","section":"Works Section","content":" First page # Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n"},{"id":131,"href":"/docs/works/works-section/second-page/","title":"Second Page","section":"Works Section","content":" Second Page # Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n"}]